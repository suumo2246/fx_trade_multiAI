# FXè‡ªå‹•ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

**ä½œæˆæ—¥**: 2025å¹´11æœˆ12æ—¥  
**ç›®çš„**: ç’°å¢ƒèªè­˜ã¨ã‚·ãƒŠãƒªã‚ªåˆ¤æ–­ã‚’è¡Œã†éšå±¤å‹æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰

---

## ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

### ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
```
Layer 1: ç’°å¢ƒèªè­˜ãƒ¢ãƒ‡ãƒ«ï¼ˆåˆ†é¡å•é¡Œï¼‰
    â†“ ã‚·ãƒŠãƒªã‚ªåˆ¤å®šï¼ˆ1_1, 1_2, 2_1, 2_2ãªã©ï¼‰
Layer 2: æˆ¦ç•¥å®Ÿè¡Œãƒ¢ãƒ‡ãƒ«ï¼ˆæœ€é©åŒ–å•é¡Œï¼‰
    â†“ ã‚¨ãƒ³ãƒˆãƒªãƒ¼/æ±ºæ¸ˆã‚¿ã‚¤ãƒŸãƒ³ã‚°æ±ºå®š
è‡ªå‹•å–å¼•å®Ÿè¡Œ
```

### å¯¾è±¡ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚·ãƒŠãƒªã‚ª
- **1_1**: ãƒˆãƒ¬ãƒ³ãƒ‰é€£ç¶š - é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯
- **1_2**: ãƒˆãƒ¬ãƒ³ãƒ‰é€£ç¶š - æŠ¼ã—ç›®ç‹™ã„
- **2_1**: ãƒ¬ãƒ³ã‚¸ãƒ–ãƒ¬ã‚¤ã‚¯ - æŠ¼ã—ç›®ï¼‹ã‚µãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³åç™º
- **2_2**: ãƒ¬ãƒ³ã‚¸ãƒ–ãƒ¬ã‚¤ã‚¯ - ã‚µãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³ãƒ–ãƒ¬ã‚¤ã‚¯
- **3_1**: ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ–ãƒ¬ã‚¤ã‚¯ - æŠ¼ã—ç›®ï¼‹ã‚µãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³åè»¢
- **3_2**: ãƒãƒ£ãƒãƒ«å†…ã‚µãƒãƒ¼ãƒˆ
- **3_3**: ãƒ¬ãƒ³ã‚¸å†…ã‚µãƒãƒ¼ãƒˆ

---

## ğŸ¯ Phase 0: ç’°å¢ƒæ§‹ç¯‰

### 0.1 é–‹ç™ºç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
```bash
# Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼ˆ3.8ä»¥ä¸Šæ¨å¥¨ï¼‰
python --version

# ä»®æƒ³ç’°å¢ƒã®ä½œæˆ
python -m venv venv
venv\Scripts\activate

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install pandas numpy matplotlib
pip install ta finta  # Windowsã®å ´åˆï¼ˆta-lib-binaryã¯åˆ©ç”¨ä¸å¯ï¼‰
pip install scikit-learn lightgbm xgboost
pip install optuna
pip install backtesting
pip install MetaTrader5  # MT5ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
pip install "mplfinance>=0.12.7a0"  # ãƒãƒ£ãƒ¼ãƒˆæç”»ç”¨
```

### 0.2 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ä½œæˆ
```
fx_ãƒˆãƒ¬ãƒ¼ãƒ‰å®Ÿç¾/
â”œâ”€â”€ data/                      # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨
â”‚   â”œâ”€â”€ raw/                   # ç”Ÿãƒ‡ãƒ¼ã‚¿
â”‚   â”œâ”€â”€ processed/             # åŠ å·¥æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
â”‚   â””â”€â”€ features/              # ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿
â”œâ”€â”€ models/                    # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ layer1/                # ç’°å¢ƒèªè­˜ãƒ¢ãƒ‡ãƒ«
â”‚   â”‚   â””â”€â”€ best_model.pkl
â”‚   â””â”€â”€ layer2/                # æˆ¦ç•¥å®Ÿè¡Œãƒ¢ãƒ‡ãƒ«ï¼ˆã‚·ãƒŠãƒªã‚ªåˆ¥ï¼‰
â”‚       â”œâ”€â”€ optimal_params.json          # å…¨ã‚·ãƒŠãƒªã‚ªã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
â”‚       â”œâ”€â”€ scenario_1_1_params.json     # ã‚·ãƒŠãƒªã‚ª1_1å°‚ç”¨
â”‚       â”œâ”€â”€ scenario_1_2_params.json     # ã‚·ãƒŠãƒªã‚ª1_2å°‚ç”¨
â”‚       â”œâ”€â”€ scenario_2_1_params.json     # ã‚·ãƒŠãƒªã‚ª2_1å°‚ç”¨
â”‚       â”œâ”€â”€ scenario_2_2_params.json     # ã‚·ãƒŠãƒªã‚ª2_2å°‚ç”¨
â”‚       â”œâ”€â”€ scenario_3_1_params.json     # ã‚·ãƒŠãƒªã‚ª3_1å°‚ç”¨
â”‚       â”œâ”€â”€ scenario_3_2_params.json     # ã‚·ãƒŠãƒªã‚ª3_2å°‚ç”¨
â”‚       â”œâ”€â”€ scenario_3_3_params.json     # ã‚·ãƒŠãƒªã‚ª3_3å°‚ç”¨
â”‚       â””â”€â”€ rl_agents/                   # å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
â”‚           â”œâ”€â”€ rl_agent_scenario_1_1.zip
â”‚           â”œâ”€â”€ rl_agent_scenario_1_2.zip
â”‚           â”œâ”€â”€ rl_agent_scenario_2_1.zip
â”‚           â”œâ”€â”€ rl_agent_scenario_2_2.zip
â”‚           â”œâ”€â”€ rl_agent_scenario_3_1.zip
â”‚           â”œâ”€â”€ rl_agent_scenario_3_2.zip
â”‚           â””â”€â”€ rl_agent_scenario_3_3.zip
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_collection/       # ãƒ‡ãƒ¼ã‚¿å–å¾—
â”‚   â”œâ”€â”€ feature_engineering/   # ç‰¹å¾´é‡ä½œæˆ
â”‚   â”œâ”€â”€ indicators/            # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™
â”‚   â”œâ”€â”€ backtesting/           # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
â”‚   â”œâ”€â”€ models/                # ãƒ¢ãƒ‡ãƒ«å®šç¾©
â”‚   â””â”€â”€ trading/               # å–å¼•å®Ÿè¡Œ
â”œâ”€â”€ notebooks/                 # Jupyter Notebook
â”œâ”€â”€ tests/                     # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
â”œâ”€â”€ config/                    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â””â”€â”€ logs/                      # ãƒ­ã‚°
```

### 0.3 ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ç¢ºç«‹
- [ ] MT5ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æº–å‚™ï¼ˆãƒ‡ãƒ¢å£åº§ã§OKï¼‰
- [ ] ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å–å¾—æ–¹æ³•ç¢ºèª
- [ ] M15, H1, H4, Dailyã®è¤‡æ•°æ™‚é–“è»¸ãƒ‡ãƒ¼ã‚¿ã®å–å¾—

---

## ğŸ”§ Phase 1: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰

**ç›®æ¨™**: AIãªã—ã§ã€è¨˜è¿°ã•ã‚ŒãŸãƒˆãƒ¬ãƒ¼ãƒ‰ãƒ«ãƒ¼ãƒ«ã‚’å®Œå…¨ã«ã‚³ãƒ¼ãƒ‰åŒ–ã—ã€ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã§ãã‚‹çŠ¶æ…‹ã«ã™ã‚‹

### 1.1 ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»å‰å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 

#### ã‚¿ã‚¹ã‚¯
- [ ] MT5ã‹ã‚‰ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ
- [ ] OHLCVï¼ˆå§‹å€¤ã€é«˜å€¤ã€å®‰å€¤ã€çµ‚å€¤ã€å‡ºæ¥é«˜ï¼‰ãƒ‡ãƒ¼ã‚¿ã®DataFrameåŒ–
- [ ] è¤‡æ•°æ™‚é–“è»¸ãƒ‡ãƒ¼ã‚¿ã®åŒæœŸå‡¦ç†
- [ ] ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆæ¬ æå€¤å‡¦ç†ã€ç•°å¸¸å€¤æ¤œå‡ºï¼‰

#### æˆæœç‰©
```python
# src/data_collection/mt5_data_collector.py
class MT5DataCollector:
    def get_historical_data(symbol, timeframe, start_date, end_date)
    def sync_multi_timeframe_data(m15_data, h1_data, h4_data, daily_data)
```

### 1.2 ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã®å®Ÿè£…

#### 1.2.1 åŸºæœ¬æŒ‡æ¨™ï¼ˆTA-Libä½¿ç”¨ï¼‰
- [ ] EMA9ã®è¨ˆç®—ï¼ˆTA-Lib: `talib.EMA()`ï¼‰
- [ ] MACDï¼ˆã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹/ãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹æ¤œå‡ºï¼‰
- [ ] ãƒ•ã‚£ãƒœãƒŠãƒƒãƒãƒªãƒˆãƒ¬ãƒ¼ã‚¹ãƒ¡ãƒ³ãƒˆè‡ªå‹•è¨ˆç®—
- [ ] ã‚µãƒãƒ¼ãƒˆ/ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ãƒ©ã‚¤ãƒ³æ¤œå‡º

#### 1.2.2 é«˜åº¦ãªæŒ‡æ¨™ï¼ˆæ‰‹å‹•å®Ÿè£… + TA-Libï¼‰
- [ ] ãƒ€ã‚¦ç†è«–ã®å®Ÿè£…
  - é«˜å€¤ãƒ»å®‰å€¤ã®æ¤œå‡ºï¼ˆZigZagã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰
  - ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šï¼ˆä¸Šæ˜‡/ä¸‹é™/ãƒ¬ãƒ³ã‚¸ï¼‰
  - ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ã‚·ã‚°ãƒŠãƒ«ï¼ˆ1,2,3æ³¢æ¤œå‡ºï¼‰
  
- [ ] Næ³¢å‹•ã®å®Ÿè£…
  - æ³¢ã®æ¤œå‡ºã¨ãƒ©ãƒ™ãƒªãƒ³ã‚°
  - Næ³¢å‹•ã®æ¯”ç‡è¨ˆç®—ï¼ˆ1:1, 1:1.6, 1:2, 1:2.618ï¼‰
  - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä¾¡æ ¼äºˆæ¸¬

- [ ] ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ»ãƒãƒ£ãƒãƒ«æ¤œå‡º
  - è‡ªå‹•ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³æç”»
  - ãƒãƒ£ãƒãƒ«ï¼ˆå¹³è¡Œç·šï¼‰ã®æ¤œå‡º
  - ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ–ãƒ¬ã‚¤ã‚¯åˆ¤å®š

- [ ] ãƒ¬ãƒ³ã‚¸æ¤œå‡º
  - ãƒ¬ãƒ³ã‚¸ç›¸å ´ã®è‡ªå‹•åˆ¤å®š
  - ãƒ¬ãƒ³ã‚¸ã®ä¸Šé™ãƒ»ä¸‹é™ç‰¹å®š
  - ãƒ¬ãƒ³ã‚¸å†…ã‚µãƒãƒ¼ãƒˆ/ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ãƒ©ã‚¤ãƒ³

- [ ] FVGï¼ˆFair Value Gapï¼‰æ¤œå‡º
  - ä¾¡æ ¼ã®é£›ã³æ¤œå‡º
  - ã‚®ãƒ£ãƒƒãƒ—ã‚¾ãƒ¼ãƒ³æç”»

- [ ] OBï¼ˆOrder Blockï¼‰æ¤œå‡º
  - å¼·ã„éœ€çµ¦ã‚¨ãƒªã‚¢ã®ç‰¹å®š

#### æˆæœç‰©
```python
# src/indicators/technical_indicators.pyï¼ˆTA-Libç‰ˆï¼‰
import talib

def calculate_ema(close, period=9):
    return talib.EMA(close, timeperiod=period)

def detect_macd_cross(close):
    macd, signal, histogram = talib.MACD(close)
    return macd, signal, histogram

def calculate_rsi(close, period=14):
    return talib.RSI(close, timeperiod=period)

def calculate_fibonacci_levels(high, low):
    # æ‰‹å‹•å®Ÿè£…ï¼ˆTA-Libã«ã¯ãªã„ï¼‰
    diff = high - low
    levels = {
        '0%': low,
        '23.6%': low + diff * 0.236,
        '38.2%': low + diff * 0.382,
        '50%': low + diff * 0.5,
        '61.8%': low + diff * 0.618,
        '100%': high
    }
    return levels

# src/indicators/advanced_indicators.pyï¼ˆæ‰‹å‹•å®Ÿè£…ï¼‰
def detect_dow_theory_trend(data):
    # ãƒ€ã‚¦ç†è«–ã®å®Ÿè£…ï¼ˆpandas-taä»£æ›¿ï¼‰
    pass

def identify_n_wave_pattern(data):
    # Næ³¢å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
    pass

def detect_support_resistance(data):
    # ã‚µãƒãƒ¼ãƒˆ/ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹è‡ªå‹•æ¤œå‡º
    pass
```

### 1.3 ãƒˆãƒ¬ãƒ¼ãƒ‰ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè£…

#### å„ã‚·ãƒŠãƒªã‚ªã®ãƒ«ãƒ¼ãƒ«å®Ÿè£…
- [ ] ã‚·ãƒŠãƒªã‚ª1_1: ãƒˆãƒ¬ãƒ³ãƒ‰é€£ç¶šãƒ»é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯
  - ãƒ€ã‚¦ç†è«–ã§ãƒˆãƒ¬ãƒ³ãƒ‰ç¢ºèª
  - é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯ã®æ¤œå‡º
  - Næ³¢å‹•ã§ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨­å®š
  - EMA9ã¨ã®ä½ç½®é–¢ä¿‚ç¢ºèª

- [ ] ã‚·ãƒŠãƒªã‚ª1_2: ãƒˆãƒ¬ãƒ³ãƒ‰é€£ç¶šãƒ»æŠ¼ã—ç›®ç‹™ã„
  - ãƒ•ã‚£ãƒœãƒŠãƒƒãƒã§æŠ¼ã—ç›®äºˆæ¸¬
  - ãƒ€ã‚¦ç†è«–ã§ãƒˆãƒ¬ãƒ³ãƒ‰ç¶­æŒç¢ºèª
  - Næ³¢å‹•ã§ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ¤å®š

- [ ] ã‚·ãƒŠãƒªã‚ª2_1: ãƒ¬ãƒ³ã‚¸ãƒ–ãƒ¬ã‚¤ã‚¯ãƒ»æŠ¼ã—ç›®ï¼‹ã‚µãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³åç™º
  - ãƒ•ã‚£ãƒœãƒŠãƒƒãƒã¨MACDã®çµ„ã¿åˆã‚ã›
  - ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹ç¢ºèª

- [ ] ã‚·ãƒŠãƒªã‚ª2_2: ãƒ¬ãƒ³ã‚¸ãƒ–ãƒ¬ã‚¤ã‚¯ãƒ»ã‚µãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³ãƒ–ãƒ¬ã‚¤ã‚¯
  - MACDå˜ç‹¬åˆ¤å®š

- [ ] ã‚·ãƒŠãƒªã‚ª3_1: ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ–ãƒ¬ã‚¤ã‚¯ãƒ»æŠ¼ã—ç›®ï¼‹ã‚µãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³åè»¢
  - ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ–ãƒ¬ã‚¤ã‚¯æ¤œå‡º
  - ãƒ€ã‚¦ç†è«–ã§ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ç¢ºèª
  - EMA9ã§ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ç¢ºèª
  - MACDã§ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç¢ºèª
  - ã‚µãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³åè»¢ãƒã‚¤ãƒ³ãƒˆç‰¹å®š

- [ ] ã‚·ãƒŠãƒªã‚ª3_2: ãƒãƒ£ãƒãƒ«å†…ã‚µãƒãƒ¼ãƒˆ
  - ãƒãƒ£ãƒãƒ«ã®æ¤œå‡ºã¨ç¢ºèª
  - ãƒãƒ£ãƒãƒ«ä¸‹é™ã§ã®ã‚µãƒãƒ¼ãƒˆåç™º
  - ãƒ•ã‚£ãƒœãƒŠãƒƒãƒã§ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆç²¾ç·»åŒ–
  - ãƒ€ã‚¦ç†è«–ã§å†…éƒ¨ãƒˆãƒ¬ãƒ³ãƒ‰ç¢ºèª

- [ ] ã‚·ãƒŠãƒªã‚ª3_3: ãƒ¬ãƒ³ã‚¸å†…ã‚µãƒãƒ¼ãƒˆ
  - ãƒ¬ãƒ³ã‚¸ç›¸å ´ã®åˆ¤å®š
  - ãƒ¬ãƒ³ã‚¸ä¸‹é™ã‚µãƒãƒ¼ãƒˆã§ã®åç™º
  - ãƒ•ã‚£ãƒœãƒŠãƒƒãƒã§ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚¿ã‚¤ãƒŸãƒ³ã‚°
  - ãƒ€ã‚¦ç†è«–ã§ãƒ¬ãƒ³ã‚¸å†…ã®å°æ³¢å‹•ç¢ºèª

#### ã‚¨ãƒ³ãƒˆãƒªãƒ¼/æ±ºæ¸ˆãƒ­ã‚¸ãƒƒã‚¯
- [ ] ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ¡ä»¶ã®å®Œå…¨å®Ÿè£…
- [ ] æåˆ‡ã‚Šï¼ˆã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ï¼‰ãƒ­ã‚¸ãƒƒã‚¯
- [ ] åˆ©ç¢ºï¼ˆãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆï¼‰ãƒ­ã‚¸ãƒƒã‚¯
- [ ] ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

#### æˆæœç‰©
```python
# src/trading/strategies.py
class Strategy_1_1_TrendBreakout:
    def check_entry_conditions(data, indicators)
    def calculate_position_size(account_balance, risk_percentage)
    def set_stop_loss(entry_price, atr)
    def set_take_profit(entry_price, n_wave_target)

class Strategy_1_2_TrendPullback:
    # åŒæ§˜ã®å®Ÿè£…

class Strategy_2_1_RangeBreakPullback:
    # åŒæ§˜ã®å®Ÿè£…

class Strategy_2_2_RangeBreakSupport:
    # åŒæ§˜ã®å®Ÿè£…

class Strategy_3_1_TrendlineBreakReversal:
    def check_trendline_break(data, indicators)
    def check_dow_reversal(data, indicators)
    def check_ema9_reversal(data, indicators)
    def check_macd_confirmation(data, indicators)
    def check_entry_conditions(data, indicators)
    def set_stop_loss(entry_price, support_level)
    def set_take_profit(entry_price, target_level)

class Strategy_3_2_ChannelSupport:
    def identify_channel(data, indicators)
    def check_channel_support(data, indicators)
    def check_fibonacci_level(data, indicators)
    def check_dow_internal_trend(data, indicators)
    def check_entry_conditions(data, indicators)
    def set_stop_loss(entry_price, channel_lower)
    def set_take_profit(entry_price, channel_upper)

class Strategy_3_3_RangeSupport:
    def identify_range(data, indicators)
    def check_range_support(data, indicators)
    def check_fibonacci_timing(data, indicators)
    def check_dow_mini_waves(data, indicators)
    def check_entry_conditions(data, indicators)
    def set_stop_loss(entry_price, range_lower)
    def set_take_profit(entry_price, range_upper)
```

### 1.4 ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰

- [ ] Backtesting.pyãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®çµ±åˆ
- [ ] å„æˆ¦ç•¥ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã®è¨ˆç®—
  - ç·æç›Šã€å‹ç‡ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
  - æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã€ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª
  - å–å¼•å›æ•°ã€å¹³å‡ä¿æœ‰æœŸé–“

- [ ] ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã®å¯è¦–åŒ–
  - æç›Šæ›²ç·š
  - ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ãƒãƒ£ãƒ¼ãƒˆ
  - å–å¼•å±¥æ­´ãƒ¬ãƒãƒ¼ãƒˆ

#### æˆæœç‰©
```python
# src/backtesting/backtest_engine.py
class BacktestEngine:
    def run_backtest(strategy, data, initial_capital)
    def calculate_metrics(trades)
    def generate_report(results)
    def plot_equity_curve(results)
```

### 1.5 ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç¢ºç«‹

- [ ] å„ã‚·ãƒŠãƒªã‚ªã®å€‹åˆ¥ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- [ ] çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆå…¨ã‚·ãƒŠãƒªã‚ªä½µç”¨ï¼‰
- [ ] å•é¡Œç‚¹ã®æ´—ã„å‡ºã—
  - å‹ç‡ãŒä½ã„ã‚·ãƒŠãƒªã‚ªã®ç‰¹å®š
  - ãƒ€ãƒã‚·ãŒå¤šã„æ¡ä»¶ã®åˆ†æ
  - éå‰°æœ€é©åŒ–ã®ç¢ºèª

#### æˆæœç‰©
- ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆï¼ˆPhase1_baseline_report.pdfï¼‰
- æ”¹å–„ã™ã¹ãèª²é¡Œãƒªã‚¹ãƒˆ
- æ¬¡ãƒ•ã‚§ãƒ¼ã‚ºã¸ã®æ¨å¥¨äº‹é …

---

## ğŸ¤– Phase 2: Layer 1ï¼ˆç’°å¢ƒèªè­˜AIï¼‰ã®é–‹ç™º

**ç›®æ¨™**: æ•™å¸«ãªã—ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¸‚å ´ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•ç™ºè¦‹ã—ã€ç’°å¢ƒèªè­˜AIã‚’æ§‹ç¯‰

**é‡è¦ãªæ–¹é‡è»¢æ›**: é™çš„ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ©ãƒ™ãƒªãƒ³ã‚°ã§ã¯ãªãã€**ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã®æ•™å¸«ãªã—ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°**ã‚’æ¡ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šï¼š
- âœ… äººé–“ã®ãƒã‚¤ã‚¢ã‚¹ã‚’æ’é™¤
- âœ… è¦‹è½ã¨ã—ã¦ã„ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç™ºè¦‹
- âœ… å¸‚å ´ã®å¤‰åŒ–ã«æŸ”è»Ÿã«å¯¾å¿œ

### 2.1 æ•™å¸«ãªã—ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹

#### 2.1.1 ç‰¹å¾´é‡ã®é¸æŠï¼ˆã‚ãªãŸã®ä½œæ¥­ï¼‰

**ã‚ãªãŸãŒã‚„ã‚‹ã“ã¨**: å¸‚å ´çŠ¶æ³ã‚’è¡¨ç¾ã™ã‚‹é‡è¦ãªæŒ‡æ¨™ã‚’é¸æŠã™ã‚‹

```python
# config/feature_selection.py
"""
ã‚ãªãŸã®ãƒˆãƒ¬ãƒ¼ãƒ‰çŸ¥è­˜ã«åŸºã¥ã„ã¦é‡è¦ãªç‰¹å¾´é‡ã‚’é¸æŠ
ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©ã¯ä¸è¦ï¼AIãŒè‡ªå‹•çš„ã«ä¼¼ãŸå¸‚å ´çŠ¶æ³ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
"""

FEATURE_GROUPS = {
    # ãƒˆãƒ¬ãƒ³ãƒ‰ç³»ï¼ˆã‚ãªãŸãŒé‡è¦–ã™ã‚‹æŒ‡æ¨™ï¼‰
    'trend_features': [
        'ema9',
        'ema21', 
        'ema200',
        'ema9_slope',  # EMAã®å‚¾ãï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ã®å¼·ã•ï¼‰
        'ema21_slope',
        'price_ema9_distance',  # ä¾¡æ ¼ã¨EMAã®ä¹–é›¢ç‡
        'price_ema21_distance',
    ],
    
    # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç³»
    'momentum_features': [
        'macd',
        'macd_signal',
        'macd_histogram',
        'rsi',
        'rsi_slope',  # RSIã®å¤‰åŒ–ç‡
        'adx',  # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
        'plus_di',  # ä¸Šæ˜‡åœ§åŠ›
        'minus_di',  # ä¸‹é™åœ§åŠ›
    ],
    
    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç³»
    'volatility_features': [
        'atr',
        'atr_normalized',  # ATR / ä¾¡æ ¼ï¼ˆæ­£è¦åŒ–ï¼‰
        'bollinger_band_width',
        'bollinger_position',  # ãƒãƒ³ãƒ‰å†…ã§ã®ä¾¡æ ¼ä½ç½®
        'price_volatility_20',  # 20æœŸé–“ã®ä¾¡æ ¼å¤‰å‹•ç‡
    ],
    
    # ä¾¡æ ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç³»
    'price_action_features': [
        'candle_body_ratio',  # å®Ÿä½“ã®å‰²åˆ
        'upper_shadow_ratio',  # ä¸Šãƒ’ã‚²ã®å‰²åˆ
        'lower_shadow_ratio',  # ä¸‹ãƒ’ã‚²ã®å‰²åˆ
        'bullish_candles_5',  # ç›´è¿‘5æœ¬ã®é™½ç·šæ•°
        'price_range_20',  # 20æœŸé–“ã®é«˜å€¤-å®‰å€¤ç¯„å›²
    ],
    
    # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆã‚ãªãŸã®æ‰‹æ³•ã®æ ¸å¿ƒï¼‰
    'multi_timeframe_features': [
        'h1_ema9_slope',  # 1æ™‚é–“è¶³ã®ãƒˆãƒ¬ãƒ³ãƒ‰
        'h4_ema9_slope',  # 4æ™‚é–“è¶³ã®ãƒˆãƒ¬ãƒ³ãƒ‰
        'daily_ema9_slope',  # æ—¥è¶³ã®ãƒˆãƒ¬ãƒ³ãƒ‰
        'h1_atr_normalized',
        'h4_atr_normalized',
        'daily_trend_alignment',  # å„æ™‚é–“è¶³ã®ãƒˆãƒ¬ãƒ³ãƒ‰ä¸€è‡´åº¦
    ],
    
    # ã‚ãªãŸã®æ‰‹æ³•å›ºæœ‰ã®ç‰¹å¾´é‡
    'custom_features': [
        'fvg_exists',  # FVGï¼ˆFair Value Gapï¼‰ã®å­˜åœ¨
        'fvg_distance',  # æœ€ã‚‚è¿‘ã„FVGã¾ã§ã®è·é›¢
        'ob_strength',  # Order Blockã®å¼·ã•
        'ob_distance',  # æœ€ã‚‚è¿‘ã„OBã¾ã§ã®è·é›¢
        'support_resistance_distance',  # ã‚µãƒãƒ¬ã‚¸ã¾ã§ã®è·é›¢
        'fibonacci_level_proximity',  # ãƒ•ã‚£ãƒœãƒŠãƒƒãƒãƒ¬ãƒ™ãƒ«ã¨ã®è¿‘ã•
    ],
    
    # å‡ºæ¥é«˜ãƒ»å¸‚å ´æ§‹é€ 
    'volume_features': [
        'volume',
        'volume_ma_ratio',  # å‡ºæ¥é«˜ç§»å‹•å¹³å‡ã¨ã®æ¯”ç‡
        'volume_trend',  # å‡ºæ¥é«˜ã®ãƒˆãƒ¬ãƒ³ãƒ‰
    ],
}

# å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã‚’é¸æŠ
SELECTED_FEATURES = (
    FEATURE_GROUPS['trend_features'] +
    FEATURE_GROUPS['momentum_features'] +
    FEATURE_GROUPS['volatility_features'] +
    FEATURE_GROUPS['multi_timeframe_features'] +
    FEATURE_GROUPS['custom_features']
)

print(f"é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡æ•°: {len(SELECTED_FEATURES)}")
```

**ä½œæ¥­ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
- [ ] ã‚ãªãŸã®ãƒˆãƒ¬ãƒ¼ãƒ‰æ‰‹æ³•ã§é‡è¦–ã—ã¦ã„ã‚‹æŒ‡æ¨™ã‚’ç¢ºèª
- [ ] ä¸Šè¨˜ãƒªã‚¹ãƒˆã‹ã‚‰ä¸è¦ãªã‚‚ã®ã‚’å‰Šé™¤
- [ ] è¿½åŠ ã—ãŸã„æŒ‡æ¨™ãŒã‚ã‚Œã°è¿½åŠ 
- [ ] åˆè¨ˆ30-50å€‹ç¨‹åº¦ã®ç‰¹å¾´é‡ã‚’é¸æŠ

#### 2.1.2 ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè£…ï¼ˆAIè‡ªå‹•ï¼‰

```python
# src/clustering/market_regime_detector.py
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns

class MarketRegimeDetector:
    """
    æ•™å¸«ãªã—ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§å¸‚å ´ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•ç™ºè¦‹
    
    ä½¿ã„æ–¹:
    1. ç‰¹å¾´é‡ã‚’æŒ‡å®š
    2. fit_clusters()ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
    3. analyze_clusters()ã§çµæœç¢ºèª
    4. ã‚ãªãŸãŒå„ã‚¯ãƒ©ã‚¹ã‚¿ã‚’è©•ä¾¡
    """
    
    def __init__(self, n_clusters=7):
        self.n_clusters = n_clusters
        self.scaler = StandardScaler()
        self.kmeans = None
        self.cluster_classifier = None
        self.feature_names = None
        self.cluster_centers = None
    
    def create_features(self, data, feature_list):
        """
        æŒ‡å®šã•ã‚ŒãŸç‰¹å¾´é‡ã‚’æŠ½å‡º
        
        Args:
            data: OHLCVãƒ‡ãƒ¼ã‚¿
            feature_list: ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ
        
        Returns:
            ç‰¹å¾´é‡DataFrame
        """
        features = pd.DataFrame(index=data.index)
        
        for feature_name in feature_list:
            if feature_name in data.columns:
                features[feature_name] = data[feature_name]
            else:
                print(f"è­¦å‘Š: {feature_name} ãŒãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ã¾ã›ã‚“")
        
        return features.fillna(method='ffill').fillna(0)
    
    def fit_clusters(self, data, feature_list):
        """
        ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        
        Args:
            data: å±¥æ­´ãƒ‡ãƒ¼ã‚¿
            feature_list: ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ
        
        Returns:
            å„ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã®ã‚¯ãƒ©ã‚¹ã‚¿ID
        """
        print(f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°é–‹å§‹: {len(feature_list)}å€‹ã®ç‰¹å¾´é‡ã‚’ä½¿ç”¨")
        
        # ç‰¹å¾´é‡ä½œæˆ
        features = self.create_features(data, feature_list)
        self.feature_names = features.columns.tolist()
        
        # æ¬ æå€¤ç¢ºèª
        if features.isnull().sum().sum() > 0:
            print("è­¦å‘Š: æ¬ æå€¤ãŒå­˜åœ¨ã—ã¾ã™ã€‚0ã§åŸ‹ã‚ã¾ã™ã€‚")
            features = features.fillna(0)
        
        # æ¨™æº–åŒ–
        features_scaled = self.scaler.fit_transform(features)
        
        # K-Meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        print(f"{self.n_clusters}å€‹ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«åˆ†é¡ä¸­...")
        self.kmeans = KMeans(
            n_clusters=self.n_clusters,
            random_state=42,
            n_init=10,
            max_iter=300
        )
        clusters = self.kmeans.fit_predict(features_scaled)
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ä¸­å¿ƒã‚’ä¿å­˜
        self.cluster_centers = self.kmeans.cluster_centers_
        
        # ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ã§å“è³ªè©•ä¾¡
        silhouette = silhouette_score(features_scaled, clusters)
        print(f"ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢: {silhouette:.3f}")
        print(f"  0.7ä»¥ä¸Š: å„ªç§€")
        print(f"  0.5-0.7: è‰¯å¥½")
        print(f"  0.25-0.5: æ™®é€š")
        print(f"  0.25æœªæº€: æ”¹å–„ãŒå¿…è¦")
        
        # XGBooståˆ†é¡å™¨ã‚’è¨“ç·´ï¼ˆæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§ã‚¯ãƒ©ã‚¹ã‚¿äºˆæ¸¬ç”¨ï¼‰
        print("ã‚¯ãƒ©ã‚¹ã‚¿åˆ†é¡å™¨ã‚’è¨“ç·´ä¸­...")
        self.cluster_classifier = xgb.XGBClassifier(
            objective='multi:softmax',
            num_class=self.n_clusters,
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1,
            random_state=42
        )
        self.cluster_classifier.fit(features, clusters)
        
        print(f"âœ“ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Œäº†")
        return clusters
    
    def predict_cluster(self, data, feature_list):
        """
        æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒ©ã‚¹ã‚¿ã‚’äºˆæ¸¬
        """
        features = self.create_features(data, feature_list)
        return self.cluster_classifier.predict(features)
    
    def analyze_clusters(self, data, clusters):
        """
        å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ç‰¹æ€§ã‚’åˆ†æ
        
        Returns:
            ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æçµæœã®è¾æ›¸
        """
        print("\n" + "="*60)
        print("ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æçµæœ")
        print("="*60)
        
        cluster_analysis = {}
        
        for i in range(self.n_clusters):
            cluster_mask = clusters == i
            cluster_data = data[cluster_mask]
            
            if len(cluster_data) == 0:
                continue
            
            # åŸºæœ¬çµ±è¨ˆ
            analysis = {
                'cluster_id': i,
                'size': len(cluster_data),
                'percentage': len(cluster_data) / len(data) * 100,
                'avg_volatility': cluster_data['atr'].mean() if 'atr' in cluster_data else 0,
                'avg_trend_strength': cluster_data['adx'].mean() if 'adx' in cluster_data else 0,
                'avg_return': cluster_data['close'].pct_change().mean(),
                'volatility_regime': self._classify_volatility(cluster_data),
                'trend_regime': self._classify_trend(cluster_data),
                'characteristics': self._describe_cluster(cluster_data)
            }
            
            cluster_analysis[i] = analysis
            
            # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
            print(f"\nã€ã‚¯ãƒ©ã‚¹ã‚¿ {i}ã€‘")
            print(f"  å‡ºç¾å›æ•°: {analysis['size']:,} ({analysis['percentage']:.1f}%)")
            print(f"  ç‰¹å¾´: {analysis['characteristics']}")
            print(f"  ãƒˆãƒ¬ãƒ³ãƒ‰: {analysis['trend_regime']}")
            print(f"  ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {analysis['volatility_regime']}")
            print(f"  å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³: {analysis['avg_return']:.4%}")
            print(f"  å¹³å‡ADX: {analysis['avg_trend_strength']:.2f}")
        
        return cluster_analysis
    
    def _classify_volatility(self, data):
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†é¡"""
        if 'atr_normalized' not in data.columns:
            return "ä¸æ˜"
        
        avg_atr = data['atr_normalized'].mean()
        if avg_atr > 0.015:
            return "è¶…é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£"
        elif avg_atr > 0.010:
            return "é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£"
        elif avg_atr > 0.005:
            return "ä¸­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£"
        else:
            return "ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£"
    
    def _classify_trend(self, data):
        """ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†é¡"""
        if 'ema9_slope' not in data.columns:
            return "ä¸æ˜"
        
        avg_slope = data['ema9_slope'].mean()
        slope_std = data['ema9_slope'].std()
        
        if abs(avg_slope) < slope_std * 0.5:
            return "ãƒ¬ãƒ³ã‚¸ãƒ»æ¨ªã°ã„"
        elif avg_slope > 0:
            if avg_slope > slope_std:
                return "å¼·ã„ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰"
            else:
                return "å¼±ã„ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰"
        else:
            if abs(avg_slope) > slope_std:
                return "å¼·ã„ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰"
            else:
                return "å¼±ã„ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰"
    
    def _describe_cluster(self, data):
        """ã‚¯ãƒ©ã‚¹ã‚¿ã®ç‰¹å¾´ã‚’æ–‡å­—åˆ—ã§èª¬æ˜"""
        trend = self._classify_trend(data)
        volatility = self._classify_volatility(data)
        return f"{trend}, {volatility}"
    
    def save(self, filepath):
        """ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        import joblib
        joblib.dump({
            'scaler': self.scaler,
            'kmeans': self.kmeans,
            'classifier': self.cluster_classifier,
            'feature_names': self.feature_names,
            'n_clusters': self.n_clusters
        }, filepath)
        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: {filepath}")
    
    def load(self, filepath):
        """ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        import joblib
        saved = joblib.load(filepath)
        self.scaler = saved['scaler']
        self.kmeans = saved['kmeans']
        self.cluster_classifier = saved['classifier']
        self.feature_names = saved['feature_names']
        self.n_clusters = saved['n_clusters']
        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿: {filepath}")
```

**å®Ÿè¡Œæ–¹æ³•**:
```python
# ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
detector = MarketRegimeDetector(n_clusters=7)
clusters = detector.fit_clusters(historical_data, SELECTED_FEATURES)

# çµæœåˆ†æ
analysis = detector.analyze_clusters(historical_data, clusters)

# ãƒ¢ãƒ‡ãƒ«ä¿å­˜
detector.save('models/layer1/market_regime_detector.pkl')
```

**ä½œæ¥­ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
- [ ] ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ
- [ ] ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ã‚’ç¢ºèªï¼ˆ0.5ä»¥ä¸ŠãŒç›®æ¨™ï¼‰
- [ ] å„ã‚¯ãƒ©ã‚¹ã‚¿ã®å‡ºç¾å›æ•°ã‚’ç¢ºèª
- [ ] åˆ†æçµæœã‚’æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ç”¨

#### 2.1.3 ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®æœ€é©åŒ–ï¼ˆAIã«ã‚ˆã‚‹è‡ªå‹•è©•ä¾¡ï¼‰

```python
# src/clustering/cluster_optimization.py
import matplotlib.pyplot as plt
from sklearn.metrics import silhouette_score, calinski_harabasz_score

def find_optimal_clusters(data, feature_list, min_clusters=5, max_clusters=12):
    """
    æœ€é©ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’è‡ªå‹•çš„ã«æ¢ç´¢
    
    Args:
        data: å±¥æ­´ãƒ‡ãƒ¼ã‚¿
        feature_list: ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ
        min_clusters: æœ€å°ã‚¯ãƒ©ã‚¹ã‚¿æ•°
        max_clusters: æœ€å¤§ã‚¯ãƒ©ã‚¹ã‚¿æ•°
    
    Returns:
        å„ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®è©•ä¾¡æŒ‡æ¨™
    """
    results = []
    
    for n in range(min_clusters, max_clusters + 1):
        print(f"\nã‚¯ãƒ©ã‚¹ã‚¿æ•° {n} ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        detector = MarketRegimeDetector(n_clusters=n)
        clusters = detector.fit_clusters(data, feature_list)
        
        # æ¨™æº–åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡
        features = detector.create_features(data, feature_list)
        features_scaled = detector.scaler.transform(features)
        
        # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
        silhouette = silhouette_score(features_scaled, clusters)
        calinski = calinski_harabasz_score(features_scaled, clusters)
        inertia = detector.kmeans.inertia_  # ã‚¯ãƒ©ã‚¹ã‚¿å†…åˆ†æ•£
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºã®ãƒãƒ©ãƒ³ã‚¹ã‚’è©•ä¾¡
        cluster_sizes = [np.sum(clusters == i) for i in range(n)]
        size_balance = np.std(cluster_sizes) / np.mean(cluster_sizes)  # å°ã•ã„ã»ã©è‰¯ã„
        
        results.append({
            'n_clusters': n,
            'silhouette_score': silhouette,
            'calinski_harabasz_score': calinski,
            'inertia': inertia,
            'size_balance': size_balance,
            'min_cluster_size': min(cluster_sizes),
            'max_cluster_size': max(cluster_sizes)
        })
        
        print(f"  ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢: {silhouette:.3f}")
        print(f"  Calinski-Harabasz ã‚¹ã‚³ã‚¢: {calinski:.1f}")
        print(f"  ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºãƒãƒ©ãƒ³ã‚¹: {size_balance:.3f}")
    
    # çµæœã‚’å¯è¦–åŒ–
    plot_cluster_metrics(results)
    
    # æ¨å¥¨ã‚¯ãƒ©ã‚¹ã‚¿æ•°
    best_n = recommend_cluster_number(results)
    print(f"\næ¨å¥¨ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {best_n}")
    
    return results

def plot_cluster_metrics(results):
    """ã‚¯ãƒ©ã‚¹ã‚¿è©•ä¾¡æŒ‡æ¨™ã®ã‚°ãƒ©ãƒ•è¡¨ç¤º"""
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    n_clusters = [r['n_clusters'] for r in results]
    
    # ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢
    axes[0, 0].plot(n_clusters, [r['silhouette_score'] for r in results], 'o-')
    axes[0, 0].set_xlabel('ã‚¯ãƒ©ã‚¹ã‚¿æ•°')
    axes[0, 0].set_ylabel('ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢')
    axes[0, 0].set_title('ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰')
    axes[0, 0].axhline(y=0.5, color='r', linestyle='--', label='ç›®æ¨™å€¤')
    axes[0, 0].legend()
    axes[0, 0].grid(True)
    
    # Calinski-Harabasz ã‚¹ã‚³ã‚¢
    axes[0, 1].plot(n_clusters, [r['calinski_harabasz_score'] for r in results], 'o-')
    axes[0, 1].set_xlabel('ã‚¯ãƒ©ã‚¹ã‚¿æ•°')
    axes[0, 1].set_ylabel('Calinski-Harabasz ã‚¹ã‚³ã‚¢')
    axes[0, 1].set_title('Calinski-Harabasz ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰')
    axes[0, 1].grid(True)
    
    # ã‚¤ãƒŠãƒ¼ã‚·ãƒ£ï¼ˆã‚¨ãƒ«ãƒœãƒ¼æ³•ï¼‰
    axes[1, 0].plot(n_clusters, [r['inertia'] for r in results], 'o-')
    axes[1, 0].set_xlabel('ã‚¯ãƒ©ã‚¹ã‚¿æ•°')
    axes[1, 0].set_ylabel('ã‚¤ãƒŠãƒ¼ã‚·ãƒ£')
    axes[1, 0].set_title('ã‚¨ãƒ«ãƒœãƒ¼æ³•ï¼ˆæ€¥æ¿€ã«æ¸›å°‘ãŒæ­¢ã¾ã‚‹ç‚¹ãŒæœ€é©ï¼‰')
    axes[1, 0].grid(True)
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºãƒãƒ©ãƒ³ã‚¹
    axes[1, 1].plot(n_clusters, [r['size_balance'] for r in results], 'o-')
    axes[1, 1].set_xlabel('ã‚¯ãƒ©ã‚¹ã‚¿æ•°')
    axes[1, 1].set_ylabel('ã‚µã‚¤ã‚ºãƒãƒ©ãƒ³ã‚¹ï¼ˆæ¨™æº–åå·®/å¹³å‡ï¼‰')
    axes[1, 1].set_title('ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºã®ãƒãƒ©ãƒ³ã‚¹ï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰')
    axes[1, 1].grid(True)
    
    plt.tight_layout()
    plt.savefig('outputs/cluster_optimization.png')
    print("âœ“ ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: outputs/cluster_optimization.png")

def recommend_cluster_number(results):
    """
    è¤‡æ•°ã®æŒ‡æ¨™ã‚’ç·åˆã—ã¦æœ€é©ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’æ¨å¥¨
    """
    # å„æŒ‡æ¨™ã‚’æ­£è¦åŒ–ã—ã¦ã‚¹ã‚³ã‚¢åŒ–
    scores = []
    
    for r in results:
        score = 0
        
        # ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ï¼ˆé‡è¦–ï¼š40%ï¼‰
        score += r['silhouette_score'] * 0.4
        
        # ã‚µã‚¤ã‚ºãƒãƒ©ãƒ³ã‚¹ï¼ˆé‡è¦–ï¼š30%ã€é€†æ•°ï¼‰
        score += (1 / (1 + r['size_balance'])) * 0.3
        
        # Calinski-Harabasz ã‚¹ã‚³ã‚¢ï¼ˆæ­£è¦åŒ–ã—ã¦20%ï¼‰
        max_calinski = max([res['calinski_harabasz_score'] for res in results])
        score += (r['calinski_harabasz_score'] / max_calinski) * 0.2
        
        # æœ€å°ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆ10%ï¼‰
        if r['min_cluster_size'] < 100:  # 100ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæœªæº€ã¯æ¸›ç‚¹
            score += 0
        else:
            score += 0.1
        
        scores.append(score)
    
    best_idx = np.argmax(scores)
    return results[best_idx]['n_clusters']
```

**å®Ÿè¡Œæ–¹æ³•**:
```python
# æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’è‡ªå‹•æ¢ç´¢
results = find_optimal_clusters(historical_data, SELECTED_FEATURES, min_clusters=5, max_clusters=12)

# æ¨å¥¨ã•ã‚ŒãŸæ•°ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
best_n = recommend_cluster_number(results)
detector = MarketRegimeDetector(n_clusters=best_n)
clusters = detector.fit_clusters(historical_data, SELECTED_FEATURES)
```

**ä½œæ¥­ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
- [ ] ã‚¯ãƒ©ã‚¹ã‚¿æ•°5-12ã§è‡ªå‹•è©•ä¾¡ã‚’å®Ÿè¡Œ
- [ ] ã‚°ãƒ©ãƒ•ã‚’ç¢ºèªï¼ˆoutputs/cluster_optimization.pngï¼‰
- [ ] æ¨å¥¨ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’ç¢ºèª
- [ ] å¿…è¦ã«å¿œã˜ã¦æ‰‹å‹•ã§èª¿æ•´

#### 2.1.4 ã‚¯ãƒ©ã‚¹ã‚¿æ¤œè¨¼ã¨ãƒ©ãƒ™ãƒªãƒ³ã‚°ï¼ˆã‚ãªãŸã®ä½œæ¥­ï¼‰

AIãŒã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ãŸçµæœã‚’æ¤œè¨¼ã—ã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã«æ„å‘³ã®ã‚ã‚‹åå‰ã‚’ä»˜ã‘ã¾ã™ã€‚

```python
# src/clustering/cluster_validation.py
import pandas as pd
import numpy as np
from backtesting import Backtest, Strategy

def validate_clusters_with_backtest(data, clusters, detector):
    """
    å„ã‚¯ãƒ©ã‚¹ã‚¿ã®å®Ÿãƒˆãƒ¬ãƒ¼ãƒ‰æ€§èƒ½ã‚’æ¤œè¨¼
    
    å„ã‚¯ãƒ©ã‚¹ã‚¿ã§ç™ºç”Ÿã—ãŸãƒˆãƒ¬ãƒ¼ãƒ‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¢ºèªã—ã€
    æœ‰åŠ¹ãªã‚¯ãƒ©ã‚¹ã‚¿ã‹ã©ã†ã‹ã‚’åˆ¤å®š
    """
    print("\n" + "="*60)
    print("ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ¤œè¨¼")
    print("="*60)
    
    validation_results = {}
    
    for cluster_id in range(detector.n_clusters):
        cluster_mask = clusters == cluster_id
        cluster_data = data[cluster_mask]
        
        if len(cluster_data) < 100:
            print(f"\nã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆ{len(cluster_data)}ä»¶ï¼‰- ã‚¹ã‚­ãƒƒãƒ—")
            continue
        
        print(f"\nã€ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id}ã€‘")
        print(f"ãƒ‡ãƒ¼ã‚¿æ•°: {len(cluster_data):,}")
        
        # Phase 1ã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æˆ¦ç•¥ã§ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
        bt = Backtest(cluster_data, Phase1Strategy, cash=10000, commission=.002)
        stats = bt.run()
        
        # é‡è¦æŒ‡æ¨™ã‚’æŠ½å‡º
        validation_results[cluster_id] = {
            'total_trades': stats['# Trades'],
            'win_rate': stats['Win Rate [%]'],
            'profit_factor': stats.get('Profit Factor', 0),
            'sharpe_ratio': stats['Sharpe Ratio'],
            'max_drawdown': stats['Max. Drawdown [%]'],
            'total_return': stats['Return [%]'],
            'avg_trade': stats['Avg. Trade [%]'],
            'is_profitable': stats['Return [%]'] > 0,
            'is_tradeable': stats['# Trades'] > 10  # æœ€ä½ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°
        }
        
        # çµæœè¡¨ç¤º
        print(f"  ç·ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°: {stats['# Trades']}")
        print(f"  å‹ç‡: {stats['Win Rate [%]']:.1f}%")
        print(f"  ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {stats['Sharpe Ratio']:.2f}")
        print(f"  æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: {stats['Max. Drawdown [%]']:.1f}%")
        print(f"  ç·ãƒªã‚¿ãƒ¼ãƒ³: {stats['Return [%]']:.1f}%")
        
        # åˆ¤å®š
        if validation_results[cluster_id]['is_profitable'] and validation_results[cluster_id]['is_tradeable']:
            print(f"  âœ“ ãƒˆãƒ¬ãƒ¼ãƒ‰å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã‚¿")
        else:
            print(f"  âœ— ãƒˆãƒ¬ãƒ¼ãƒ‰éæ¨å¥¨")
    
    return validation_results

def analyze_cluster_characteristics(data, clusters, detector):
    """
    å„ã‚¯ãƒ©ã‚¹ã‚¿ã®å¸‚å ´ç‰¹æ€§ã‚’è©³ç´°åˆ†æ
    
    ã‚ãªãŸãŒãƒ©ãƒ™ãƒ«ä»˜ã‘ã™ã‚‹ãŸã‚ã®æƒ…å ±ã‚’æä¾›
    """
    print("\n" + "="*60)
    print("ã‚¯ãƒ©ã‚¹ã‚¿ç‰¹æ€§ã®è©³ç´°åˆ†æ")
    print("="*60)
    
    for cluster_id in range(detector.n_clusters):
        cluster_mask = clusters == cluster_id
        cluster_data = data[cluster_mask]
        
        if len(cluster_data) == 0:
            continue
        
        print(f"\n{'='*60}")
        print(f"ã€ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id}ã€‘")
        print(f"{'='*60}")
        
        # 1. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        print("\nâ–  ãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹æ€§:")
        if 'ema9_slope' in cluster_data.columns:
            avg_slope = cluster_data['ema9_slope'].mean()
            slope_direction = "ä¸Šæ˜‡" if avg_slope > 0 else "ä¸‹é™"
            slope_strength = "å¼·ã„" if abs(avg_slope) > cluster_data['ema9_slope'].std() else "å¼±ã„"
            print(f"  EMA9å‚¾ã: {slope_direction} {slope_strength} ({avg_slope:.6f})")
        
        if 'adx' in cluster_data.columns:
            avg_adx = cluster_data['adx'].mean()
            trend_strength = "å¼·ãƒˆãƒ¬ãƒ³ãƒ‰" if avg_adx > 25 else "ãƒ¬ãƒ³ã‚¸" if avg_adx < 15 else "ä¸­ç¨‹åº¦"
            print(f"  ADX: {avg_adx:.1f} ({trend_strength})")
        
        # 2. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ
        print("\nâ–  ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£:")
        if 'atr_normalized' in cluster_data.columns:
            avg_atr = cluster_data['atr_normalized'].mean()
            vol_level = "è¶…é«˜" if avg_atr > 0.015 else "é«˜" if avg_atr > 0.010 else "ä¸­" if avg_atr > 0.005 else "ä½"
            print(f"  ATRæ­£è¦åŒ–: {avg_atr:.4f} ({vol_level})")
        
        # 3. ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ åˆ†æ
        print("\nâ–  ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ :")
        if 'rsi' in cluster_data.columns:
            avg_rsi = cluster_data['rsi'].mean()
            rsi_state = "è²·ã‚ã‚Œéã" if avg_rsi > 70 else "å£²ã‚‰ã‚Œéã" if avg_rsi < 30 else "ä¸­ç«‹"
            print(f"  RSI: {avg_rsi:.1f} ({rsi_state})")
        
        if 'macd_histogram' in cluster_data.columns:
            avg_macd_hist = cluster_data['macd_histogram'].mean()
            macd_state = "å¼·æ°—" if avg_macd_hist > 0 else "å¼±æ°—"
            print(f"  MACDãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ : {avg_macd_hist:.4f} ({macd_state})")
        
        # 4. ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æ
        print("\nâ–  ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ :")
        for tf in ['h1', 'h4', 'daily']:
            col = f'{tf}_ema9_slope'
            if col in cluster_data.columns:
                avg = cluster_data[col].mean()
                direction = "â†‘ä¸Šæ˜‡" if avg > 0 else "â†“ä¸‹é™"
                print(f"  {tf.upper()}: {direction} ({avg:.6f})")
        
        # 5. ä¾¡æ ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ†æ
        print("\nâ–  ä¾¡æ ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
        if 'candle_body_ratio' in cluster_data.columns:
            avg_body = cluster_data['candle_body_ratio'].mean()
            print(f"  å®Ÿä½“æ¯”ç‡: {avg_body:.2f} ({'å¤§ãã„å®Ÿä½“' if avg_body > 0.6 else 'å°ã•ã„å®Ÿä½“'})")
        
        # 6. å‡ºç¾ã‚¿ã‚¤ãƒŸãƒ³ã‚°
        print("\nâ–  å‡ºç¾ãƒ‘ã‚¿ãƒ¼ãƒ³:")
        print(f"  å‡ºç¾å›æ•°: {len(cluster_data):,}")
        print(f"  å…¨ä½“ã«å ã‚ã‚‹å‰²åˆ: {len(cluster_data) / len(data) * 100:.1f}%")
        
        # æ™‚ç³»åˆ—ã§ã®åˆ†å¸ƒ
        cluster_data_with_dates = cluster_data.copy()
        if 'date' in cluster_data_with_dates.columns:
            monthly_counts = cluster_data_with_dates.groupby(cluster_data_with_dates['date'].dt.to_period('M')).size()
            print(f"  æœˆé–“å¹³å‡å‡ºç¾: {monthly_counts.mean():.0f}å›")
        
        print("\n" + "-"*60)
        print("ã‚ãªãŸã®ä½œæ¥­: ä¸Šè¨˜ã®ç‰¹æ€§ã‹ã‚‰ã€ã“ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«åå‰ã‚’ä»˜ã‘ã¦ãã ã•ã„")
        print("ä¾‹: 'å¼·ã„ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»é«˜ãƒœãƒ©', 'ãƒ¬ãƒ³ã‚¸ç›¸å ´ãƒ»ä½ãƒœãƒ©', 'åè»¢å±€é¢' ãªã©")

def create_cluster_labels(detector):
    """
    ã‚ãªãŸãŒã‚¯ãƒ©ã‚¹ã‚¿ã«åå‰ã‚’ä»˜ã‘ã‚‹ãŸã‚ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    """
    cluster_labels = {}
    
    print("\n" + "="*60)
    print("ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒªãƒ³ã‚°")
    print("="*60)
    
    for i in range(detector.n_clusters):
        print(f"\nã‚¯ãƒ©ã‚¹ã‚¿ {i} ã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")
        print("ï¼ˆä¸Šè¨˜ã®åˆ†æçµæœã‚’å‚è€ƒã«ã€ã‚ã‹ã‚Šã‚„ã™ã„åå‰ã‚’ä»˜ã‘ã¦ãã ã•ã„ï¼‰")
        label = input(f"ã‚¯ãƒ©ã‚¹ã‚¿ {i}: ")
        cluster_labels[i] = label if label else f"ã‚¯ãƒ©ã‚¹ã‚¿_{i}"
    
    # ä¿å­˜
    import json
    with open('config/cluster_labels.json', 'w', encoding='utf-8') as f:
        json.dump(cluster_labels, f, ensure_ascii=False, indent=2)
    
    print("\nâœ“ ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    return cluster_labels
```

**ä½œæ¥­ãƒ•ãƒ­ãƒ¼**:
```python
# 1. ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã§æ¤œè¨¼
validation_results = validate_clusters_with_backtest(
    historical_data, 
    clusters, 
    detector
)

# 2. å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ç‰¹æ€§ã‚’è©³ç´°åˆ†æ
analyze_cluster_characteristics(historical_data, clusters, detector)

# 3. ã‚ãªãŸãŒãƒ©ãƒ™ãƒ«ã‚’ä»˜ã‘ã‚‹
cluster_labels = create_cluster_labels(detector)

# 4. ãƒˆãƒ¬ãƒ¼ãƒ‰ä¸å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã‚¿ã‚’é™¤å¤–
tradeable_clusters = [
    cid for cid, result in validation_results.items()
    if result['is_profitable'] and result['is_tradeable']
]

print(f"\nãƒˆãƒ¬ãƒ¼ãƒ‰å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã‚¿: {tradeable_clusters}")
```

**ä½œæ¥­ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
- [ ] å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚’ç¢ºèª
- [ ] å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ç‰¹æ€§åˆ†æã‚’èª­ã‚€
- [ ] å„ã‚¯ãƒ©ã‚¹ã‚¿ã«æ„å‘³ã®ã‚ã‚‹åå‰ã‚’ä»˜ã‘ã‚‹
- [ ] ãƒˆãƒ¬ãƒ¼ãƒ‰ä¸å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã‚¿ã‚’ç‰¹å®š
- [ ] ãƒ©ãƒ™ãƒ«ã‚’config/cluster_labels.jsonã«ä¿å­˜

**ä¾‹ï¼šãƒ©ãƒ™ãƒªãƒ³ã‚°çµæœ**:
```json
{
  "0": "å¼·ã„ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£",
  "1": "å¼±ã„ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£",
  "2": "ãƒ¬ãƒ³ã‚¸ç›¸å ´ãƒ»ä¸­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£",
  "3": "ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£",
  "4": "ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›å±€é¢",
  "5": "èª¿æ•´å±€é¢ãƒ»æŠ¼ã—ç›®å€™è£œ",
  "6": "å¾…æ©Ÿæ¨å¥¨ãƒ»ä¸æ˜ç­"
}
```

---

### 2.2 æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆï¼ˆå¾“æ¥å‹ - å‚è€ƒç”¨ï¼‰

**æ³¨æ„**: ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯å¾“æ¥ã®é™çš„ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã™ã€‚æ•™å¸«ãªã—ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’ä½¿ã†å ´åˆã¯ä¸è¦ã§ã™ãŒã€å‚è€ƒã¨ã—ã¦æ®‹ã—ã¦ã„ã¾ã™ã€‚

#### 2.1.1 ãƒ©ãƒ™ãƒªãƒ³ã‚°æˆ¦ç•¥
- [ ] Phase 1ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‹ã‚‰å‹ã¡ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚’æŠ½å‡º
- [ ] å„å‹ã¡ãƒˆãƒ¬ãƒ¼ãƒ‰ãŒç™ºç”Ÿã—ãŸæ™‚ç‚¹ã®ç›¸å ´çŠ¶æ³ã‚’è¨˜éŒ²
- [ ] ã‚·ãƒŠãƒªã‚ªã”ã¨ã«ãƒ©ãƒ™ãƒ«ä»˜ã‘
  - Class 0: ãƒãƒ¼ã‚¨ãƒ³ãƒˆãƒªãƒ¼ï¼ˆå¾…æ©Ÿï¼‰
  - Class 1: ã‚·ãƒŠãƒªã‚ª1_1ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰é€£ç¶šãƒ»é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯ï¼‰
  - Class 2: ã‚·ãƒŠãƒªã‚ª1_2ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰é€£ç¶šãƒ»æŠ¼ã—ç›®ï¼‰
  - Class 3: ã‚·ãƒŠãƒªã‚ª2_1ï¼ˆãƒ¬ãƒ³ã‚¸ãƒ–ãƒ¬ã‚¤ã‚¯ãƒ»æŠ¼ã—ç›®ï¼‹ã‚µãƒãƒ¼ãƒˆåç™ºï¼‰
  - Class 4: ã‚·ãƒŠãƒªã‚ª2_2ï¼ˆãƒ¬ãƒ³ã‚¸ãƒ–ãƒ¬ã‚¤ã‚¯ãƒ»ã‚µãƒãƒ¼ãƒˆãƒ–ãƒ¬ã‚¤ã‚¯ï¼‰
  - Class 5: ã‚·ãƒŠãƒªã‚ª3_1ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ–ãƒ¬ã‚¤ã‚¯ãƒ»åè»¢ï¼‰
  - Class 6: ã‚·ãƒŠãƒªã‚ª3_2ï¼ˆãƒãƒ£ãƒãƒ«å†…ã‚µãƒãƒ¼ãƒˆï¼‰
  - Class 7: ã‚·ãƒŠãƒªã‚ª3_3ï¼ˆãƒ¬ãƒ³ã‚¸å†…ã‚µãƒãƒ¼ãƒˆï¼‰

#### 2.1.2 ãƒ©ãƒ™ãƒªãƒ³ã‚°åŸºæº–ã®æ˜ç¢ºåŒ–
```python
# ä¾‹: ã‚·ãƒŠãƒªã‚ª1_1ã®ãƒ©ãƒ™ãƒªãƒ³ã‚°åŸºæº–
def label_scenario_1_1(data, index):
    """
    ä»¥ä¸‹ã®æ¡ä»¶ã‚’ã™ã¹ã¦æº€ãŸã™å ´åˆã«1ã‚’è¿”ã™ï¼š
    1. ãƒ€ã‚¦ç†è«–ã§ã‚¢ãƒƒãƒ—ãƒˆãƒ¬ãƒ³ãƒ‰ç¢ºèª
    2. ç›´è¿‘é«˜å€¤ã‚’ãƒ–ãƒ¬ã‚¤ã‚¯
    3. Næ³¢å‹•ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«åˆ°é”
    4. EMA9ã‚ˆã‚Šä¸Š
    5. å®Ÿéš›ã«åˆ©ç›ŠãŒå‡ºãŸ
    """
```

- [ ] å„ã‚·ãƒŠãƒªã‚ªã®ãƒ©ãƒ™ãƒªãƒ³ã‚°é–¢æ•°ä½œæˆ
- [ ] è‡ªå‹•ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
- [ ] æ‰‹å‹•æ¤œè¨¼ã¨ãƒ©ãƒ™ãƒ«è£œæ­£

### 2.2 ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

#### 2.2.1 åŸºæœ¬ç‰¹å¾´é‡
- [ ] ä¾¡æ ¼ç³»: ç¾åœ¨ä¾¡æ ¼ã€é«˜å€¤ã€å®‰å€¤ã€çµ‚å€¤
- [ ] ãƒˆãƒ¬ãƒ³ãƒ‰ç³»: EMA9, EMA21, EMA200ã¨ã®ä¹–é›¢ç‡
- [ ] ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç³»: RSI, MACD, ADX
- [ ] ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç³»: ATR, ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰å¹…

#### 2.2.2 é«˜åº¦ãªç‰¹å¾´é‡ï¼ˆæœ€é‡è¦ï¼‰
- [ ] ãƒ€ã‚¦ç†è«–ç‰¹å¾´é‡
  - ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘ï¼ˆ1: ä¸Šæ˜‡, 0: ãƒ¬ãƒ³ã‚¸, -1: ä¸‹é™ï¼‰
  - é«˜å€¤åˆ‡ã‚Šä¸Šã’é€£ç¶šå›æ•°
  - å®‰å€¤åˆ‡ã‚Šä¸Šã’é€£ç¶šå›æ•°
  - æœ€å¾Œã®ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ã‹ã‚‰ã®çµŒéãƒãƒ¼æ•°

- [ ] Næ³¢å‹•ç‰¹å¾´é‡
  - ç¾åœ¨ã®æ³¢ã®æ®µéšï¼ˆ1æ³¢, 2æ³¢, 3æ³¢ï¼‰
  - å‰æ³¢ã«å¯¾ã™ã‚‹ç¾åœ¨æ³¢ã®æ¯”ç‡
  - ç†æƒ³çš„ãªNæ³¢å‹•æ¯”ç‡ã¨ã®ä¹–é›¢åº¦
  - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä¾¡æ ¼ã¾ã§ã®è·é›¢ï¼ˆpipsï¼‰

- [ ] ãƒ•ã‚£ãƒœãƒŠãƒƒãƒç‰¹å¾´é‡
  - å„ãƒ¬ãƒ™ãƒ«ï¼ˆ23.6%, 38.2%, 50%, 61.8%ï¼‰ã¾ã§ã®è·é›¢
  - æœ€ã‚‚è¿‘ã„ãƒ•ã‚£ãƒœãƒŠãƒƒãƒãƒ¬ãƒ™ãƒ«
  - ãƒ•ã‚£ãƒœãƒŠãƒƒãƒã‚¾ãƒ¼ãƒ³å†…ã‹ã©ã†ã‹ï¼ˆãƒã‚¤ãƒŠãƒªï¼‰

- [ ] ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ç‰¹å¾´é‡
  - H1ã®ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘
  - H4ã®ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘
  - Dailyã®ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘
  - ä¸Šä½è¶³ã®ä¸»è¦ã‚µãƒãƒ¼ãƒˆ/ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ã¾ã§ã®è·é›¢

- [ ] FVG/OBç‰¹å¾´é‡
  - ç›´è¿‘ã®FVGã¾ã§ã®è·é›¢
  - FVGã‚¾ãƒ¼ãƒ³å†…ã‹ã©ã†ã‹
  - ç›´è¿‘ã®OBã¾ã§ã®è·é›¢
  - OBã®å¼·åº¦ï¼ˆå‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ï¼‰

- [ ] ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ»ãƒãƒ£ãƒãƒ«ç‰¹å¾´é‡
  - ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã®è§’åº¦
  - ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã¾ã§ã®è·é›¢
  - ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ–ãƒ¬ã‚¤ã‚¯åˆ¤å®š
  - ãƒãƒ£ãƒãƒ«å¹…
  - ãƒãƒ£ãƒãƒ«å†…ã®ä½ç½®ï¼ˆä¸Šéƒ¨/ä¸­éƒ¨/ä¸‹éƒ¨ï¼‰

- [ ] ãƒ¬ãƒ³ã‚¸ç‰¹å¾´é‡
  - ãƒ¬ãƒ³ã‚¸åˆ¤å®šãƒ•ãƒ©ã‚°
  - ãƒ¬ãƒ³ã‚¸å¹…
  - ãƒ¬ãƒ³ã‚¸å†…ã®ä½ç½®
  - ãƒ¬ãƒ³ã‚¸ç¶™ç¶šæœŸé–“

#### æˆæœç‰©
```python
# src/feature_engineering/feature_creator.py
class FeatureCreator:
    def create_basic_features(data)
    def create_dow_theory_features(data)
    def create_n_wave_features(data)
    def create_fibonacci_features(data)
    def create_multi_timeframe_features(m15, h1, h4, daily)
    def create_fvg_ob_features(data)
    def create_trendline_channel_features(data)
    def create_range_features(data)
    def create_all_features(data)  # çµ±åˆ
```

### 2.3 ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨è©•ä¾¡

#### 2.3.1 ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
- [ ] æ™‚ç³»åˆ—ã‚’è€ƒæ…®ã—ãŸåˆ†å‰²ï¼ˆTimeSeriesSplitï¼‰
- [ ] è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 70%
- [ ] æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: 15%
- [ ] ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 15%

#### 2.3.2 ãƒ¢ãƒ‡ãƒ«é¸å®šã¨å­¦ç¿’
- [ ] XGBoostã®å®Ÿè£…ï¼ˆãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼‰
  ```python
  import xgboost as xgb
  
  model = xgb.XGBClassifier(
      objective='multi:softmax',
      num_class=8,  # ã‚·ãƒŠãƒªã‚ªæ•°ï¼ˆ0: å¾…æ©Ÿ + 7ã‚·ãƒŠãƒªã‚ªï¼‰
      n_estimators=500,
      learning_rate=0.05,
      max_depth=7,
      subsample=0.8,
      colsample_bytree=0.8,
      tree_method='hist',  # é«˜é€ŸåŒ–
      eval_metric='mlogloss'
  )
  ```

- [ ] ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ï¼ˆæ¯”è¼ƒç”¨ï¼‰
  - ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼ˆç²¾åº¦æ¯”è¼ƒï¼‰
  - ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰

#### 2.3.3 ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- [ ] Optunaã«ã‚ˆã‚‹è‡ªå‹•æœ€é©åŒ–
  ```python
  def objective(trial):
      params = {
          'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
          'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
          'max_depth': trial.suggest_int('max_depth', 3, 10),
          'num_leaves': trial.suggest_int('num_leaves', 20, 100)
      }
      # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨è©•ä¾¡
      return accuracy
  ```

#### 2.3.4 ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
- [ ] ç²¾åº¦ï¼ˆAccuracyï¼‰
- [ ] å„ã‚¯ãƒ©ã‚¹ã®é©åˆç‡ãƒ»å†ç¾ç‡ãƒ»F1ã‚¹ã‚³ã‚¢
- [ ] æ··åŒè¡Œåˆ—ï¼ˆConfusion Matrixï¼‰
- [ ] ç‰¹å¾´é‡é‡è¦åº¦ã®åˆ†æ

#### æˆæœç‰©
```python
# src/models/layer1_environment_classifier.py
class EnvironmentClassifier:
    def __init__(self, model_type='xgboost')
    def train(X_train, y_train, X_val, y_val)
    def predict(X)
    def predict_proba(X)  # ç¢ºç‡å‡ºåŠ›
    def save_model(path)
    def load_model(path)
```

### 2.4 çµ±åˆã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ

- [ ] Layer 1ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã«çµ±åˆ
- [ ] ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè£…
  ```python
  # ä¾‹: äºˆæ¸¬ç¢ºç‡ãŒ60%ä»¥ä¸Šã®æ™‚ã ã‘ã‚¨ãƒ³ãƒˆãƒªãƒ¼è¨±å¯
  if predicted_proba > 0.6:
      execute_scenario(predicted_scenario)
  ```

- [ ] çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- [ ] Phase 1ï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰ã¨ã®æ¯”è¼ƒ
  - å‹ç‡ã®å‘ä¸Š
  - ãƒ€ãƒã‚·ãƒˆãƒ¬ãƒ¼ãƒ‰ã®æ¸›å°‘
  - ç·æç›Šã®æ”¹å–„

#### æˆæœç‰©
- Layer1çµ±åˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆï¼ˆPhase2_layer1_report.pdfï¼‰
- ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
- ç‰¹å¾´é‡é‡è¦åº¦ãƒ¬ãƒãƒ¼ãƒˆ

---

## âš™ï¸ Phase 3: Layer 2ï¼ˆæˆ¦ç•¥å®Ÿè¡Œæœ€é©åŒ–ï¼‰ã®é–‹ç™º

**ç›®æ¨™**: å„ã‚¯ãƒ©ã‚¹ã‚¿ã«ãŠã‘ã‚‹ã‚¨ãƒ³ãƒˆãƒªãƒ¼/æ±ºæ¸ˆåˆ¤æ–­ã‚’å¼·åŒ–å­¦ç¿’ã§å‹•çš„æœ€é©åŒ–

**æ¡ç”¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**: **ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«** - Phase 2ã§ç™ºè¦‹ã—ãŸå„ã‚¯ãƒ©ã‚¹ã‚¿ï¼ˆå¸‚å ´ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ã”ã¨ã«ç‹¬ç«‹ã—ãŸå¼·åŒ–å­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´ã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æœ€é©ãªå–å¼•åˆ¤æ–­ã‚’è¡Œã„ã¾ã™ã€‚

**é‡è¦ãªå¤‰æ›´ç‚¹**: 
- âŒ å¾“æ¥: æ‰‹å‹•å®šç¾©ã—ãŸ7ã‚·ãƒŠãƒªã‚ªã”ã¨ã«RL
- âœ… æ–°æ–¹å¼: AIãŒç™ºè¦‹ã—ãŸã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«RL

**ãƒ¡ãƒªãƒƒãƒˆ**:
- ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è‡ªå‹•çš„ã«æœ€é©ãªå¸‚å ´åˆ†é¡ã‚’ç™ºè¦‹
- äººé–“ã®å®šç¾©ã«ç¸›ã‚‰ã‚Œãªã„æŸ”è»Ÿãªãƒˆãƒ¬ãƒ¼ãƒ‰
- æ–°ã—ã„å¸‚å ´ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚‚å¯¾å¿œå¯èƒ½

### 3.1 ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥å¼·åŒ–å­¦ç¿’ã®è¨­è¨ˆ

#### 3.1.1 ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç©ºé–“ã®å®šç¾©ï¼ˆå…¨ã‚¯ãƒ©ã‚¹ã‚¿å…±é€šï¼‰

```python
# src/rl/action_space.py
"""
å…¨ã‚¯ãƒ©ã‚¹ã‚¿ã§å…±é€šã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç©ºé–“
ï¼ˆå¿…è¦ã«å¿œã˜ã¦ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ï¼‰
"""

ACTION_SPACE = {
    0: 'HOLD',           # ä½•ã‚‚ã—ãªã„ï¼ˆå¾…æ©Ÿï¼‰
    1: 'BUY_SMALL',      # å°ãƒ­ãƒƒãƒˆã§ã‚¨ãƒ³ãƒˆãƒªãƒ¼ (0.01 lot)
    2: 'BUY_MEDIUM',     # ä¸­ãƒ­ãƒƒãƒˆã§ã‚¨ãƒ³ãƒˆãƒªãƒ¼ (0.03 lot)
    3: 'BUY_LARGE',      # å¤§ãƒ­ãƒƒãƒˆã§ã‚¨ãƒ³ãƒˆãƒªãƒ¼ (0.05 lot)
    4: 'CLOSE_HALF',     # ãƒã‚¸ã‚·ãƒ§ãƒ³ã®åŠåˆ†ã‚’æ±ºæ¸ˆ
    5: 'CLOSE_ALL',      # å…¨ãƒã‚¸ã‚·ãƒ§ãƒ³æ±ºæ¸ˆ
    6: 'TRAILING_STOP',  # ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—æœ‰åŠ¹åŒ–
}

# ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºä¾‹
CLUSTER_ACTION_CUSTOMIZATION = {
    # ä¾‹: "å¼·ã„ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»é«˜ãƒœãƒ©"ã‚¯ãƒ©ã‚¹ã‚¿
    0: {
        'allowed_actions': [0, 1, 2, 3, 5, 6],  # å…¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¨±å¯
        'lot_sizes': {'small': 0.01, 'medium': 0.03, 'large': 0.05},
        'trailing_stop_distance': 50  # pips
    },
    
    # ä¾‹: "ãƒ¬ãƒ³ã‚¸ç›¸å ´ãƒ»ä½ãƒœãƒ©"ã‚¯ãƒ©ã‚¹ã‚¿
    2: {
        'allowed_actions': [0, 1, 4, 5],  # æ…é‡ãªè¡Œå‹•ã®ã¿
        'lot_sizes': {'small': 0.01, 'medium': 0.02, 'large': 0.03},
        'trailing_stop_distance': 30
    },
    
    # ä¾‹: "å¾…æ©Ÿæ¨å¥¨"ã‚¯ãƒ©ã‚¹ã‚¿
    6: {
        'allowed_actions': [0, 5],  # å¾…æ©Ÿ or æ—¢å­˜ãƒã‚¸ã‚·ãƒ§ãƒ³æ±ºæ¸ˆã®ã¿
        'lot_sizes': {'small': 0, 'medium': 0, 'large': 0},
        'trailing_stop_distance': 0
    }
}
```
```

**ã‚·ãƒŠãƒªã‚ªåˆ¥ã®æ‹¡å¼µã‚¢ã‚¯ã‚·ãƒ§ãƒ³**
- ã‚·ãƒŠãƒªã‚ª1_1ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆï¼‰: ãƒ–ãƒ¬ã‚¤ã‚¯ç¢ºèªå¾Œã®è¿½åŠ ã‚¨ãƒ³ãƒˆãƒªãƒ¼
- ã‚·ãƒŠãƒªã‚ª1_2ï¼ˆæŠ¼ã—ç›®ï¼‰: è¤‡æ•°ãƒ•ã‚£ãƒœãƒŠãƒƒãƒãƒ¬ãƒ™ãƒ«ã§ã®åˆ†å‰²ã‚¨ãƒ³ãƒˆãƒªãƒ¼
- ã‚·ãƒŠãƒªã‚ª3_2ï¼ˆãƒãƒ£ãƒãƒ«ï¼‰: ãƒãƒ£ãƒãƒ«ä¸Šé™æ¥è¿‘æ™‚ã®éƒ¨åˆ†åˆ©ç¢º

#### 3.1.2 è¦³æ¸¬ç©ºé–“ã®è¨­è¨ˆ

**å„ã‚·ãƒŠãƒªã‚ªã§è¦³æ¸¬ã™ã‚‹ç‰¹å¾´é‡**
```python
# ã‚·ãƒŠãƒªã‚ªã”ã¨ã«é–¢é€£ã™ã‚‹ç‰¹å¾´é‡ã®ã¿ã‚’è¦³æ¸¬
observation_features = {
    'price_features': [
        'current_price',
        'high', 'low', 'close',
        'price_change_pct'
    ],
    'technical_indicators': [
        'ema9', 'ema21', 'ema200',
        'macd', 'macd_signal', 'macd_hist',
        'rsi', 'atr', 'adx'
    ],
    'scenario_specific': [
        # ã‚·ãƒŠãƒªã‚ª1_1ã®å ´åˆ
        'breakout_strength',
        'n_wave_ratio',
        'ema9_distance',
        # ã‚·ãƒŠãƒªã‚ª3_2ã®å ´åˆ
        'channel_position',  # ãƒãƒ£ãƒãƒ«å†…ã®ä½ç½®
        'channel_width',
        'support_distance'
    ],
    'position_info': [
        'has_position',
        'position_size',
        'unrealized_pnl',
        'holding_bars'
    ]
}
```

#### 3.1.3 å ±é…¬é–¢æ•°ã®è¨­è¨ˆï¼ˆæœ€é‡è¦ï¼‰

**åŸºæœ¬å ±é…¬æ§‹é€ **
```python
def calculate_reward(action, state, next_state):
    """
    ã‚·ãƒŠãƒªã‚ªã«å¿œã˜ãŸå ±é…¬è¨ˆç®—
    """
    reward = 0
    
    # 1. åˆ©ç›Šå ±é…¬ï¼ˆæœ€é‡è¦ï¼‰
    pnl = next_state['unrealized_pnl'] - state['unrealized_pnl']
    reward += pnl * 10  # åˆ©ç›Šã‚’å¼·ãè©•ä¾¡
    
    # 2. ãƒªã‚¹ã‚¯ç®¡ç†å ±é…¬
    if action in ['CLOSE_HALF', 'CLOSE_ALL']:
        if pnl > 0:
            reward += 5  # åˆ©ç¢ºã‚’è©•ä¾¡
        elif pnl < -state['max_loss']:
            reward += 3  # é©åˆ‡ãªæåˆ‡ã‚Šã‚’è©•ä¾¡
    
    # 3. å–å¼•åŠ¹ç‡å ±é…¬
    if action == 'HOLD' and not state['has_position']:
        if state['scenario_probability'] < 0.6:
            reward += 1  # ä½ç¢ºç‡æ™‚ã®å¾…æ©Ÿã‚’è©•ä¾¡
    
    # 4. ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ãƒšãƒŠãƒ«ãƒ†ã‚£
    if state['drawdown'] > 0.1:  # 10%ä»¥ä¸Šã®ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
        reward -= 10
    
    # 5. ã‚·ãƒŠãƒªã‚ªå›ºæœ‰ã®å ±é…¬
    # ä¾‹: ã‚·ãƒŠãƒªã‚ª1_1ã®å ´åˆ
    if scenario == '1_1':
        if action in ['BUY_MEDIUM', 'BUY_LARGE']:
            if state['breakout_confirmed']:
                reward += 3  # ãƒ–ãƒ¬ã‚¤ã‚¯ç¢ºèªå¾Œã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’è©•ä¾¡
    
    # ä¾‹: ã‚·ãƒŠãƒªã‚ª3_2ã®å ´åˆ
    if scenario == '3_2':
        if action == 'CLOSE_HALF':
            if state['channel_position'] > 0.8:  # ãƒãƒ£ãƒãƒ«ä¸Šé™ä»˜è¿‘
                reward += 4  # ä¸Šé™ã§ã®éƒ¨åˆ†åˆ©ç¢ºã‚’è©•ä¾¡
    
    return reward
```

**ã‚·ãƒŠãƒªã‚ªåˆ¥å ±é…¬ã®èª¿æ•´ãƒã‚¤ãƒ³ãƒˆï¼ˆå‚è€ƒï¼‰**
- [ ] ã‚·ãƒŠãƒªã‚ª1_1: ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã®å‹¢ã„ã‚’è©•ä¾¡
- [ ] ã‚·ãƒŠãƒªã‚ª1_2: ãƒ•ã‚£ãƒœãƒŠãƒƒãƒãƒ¬ãƒ™ãƒ«ã§ã®åç™ºã‚’è©•ä¾¡
- [ ] ã‚·ãƒŠãƒªã‚ª2_1: MACDã‚¯ãƒ­ã‚¹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’è©•ä¾¡
- [ ] ã‚·ãƒŠãƒªã‚ª2_2: ãƒ–ãƒ¬ã‚¤ã‚¯å¾Œã®ç¶™ç¶šæ€§ã‚’è©•ä¾¡
- [ ] ã‚·ãƒŠãƒªã‚ª3_1: ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ã®ç¢ºå®Ÿæ€§ã‚’è©•ä¾¡
- [ ] ã‚·ãƒŠãƒªã‚ª3_2: ãƒãƒ£ãƒãƒ«å†…ã®ä½ç½®å–ã‚Šã‚’è©•ä¾¡
- [ ] ã‚·ãƒŠãƒªã‚ª3_3: ãƒ¬ãƒ³ã‚¸å¢ƒç•Œã§ã®åç™ºã‚’è©•ä¾¡

---

### 3.2 ã€å‚è€ƒã€‘ã‚·ãƒŠãƒªã‚ªåˆ¥ç’°å¢ƒå®Ÿè£…ï¼ˆå¾“æ¥å‹ï¼‰

ä»¥ä¸‹ã¯å¾“æ¥ã®ã‚·ãƒŠãƒªã‚ªãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã™ã€‚ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ–¹å¼ã§ã¯ä¸è¦ã§ã™ãŒã€å‚è€ƒã¨ã—ã¦æ®‹ã—ã¦ã„ã¾ã™ã€‚

### 3.2 ã€å‚è€ƒã€‘ã‚·ãƒŠãƒªã‚ªåˆ¥ç’°å¢ƒå®Ÿè£…ï¼ˆå¾“æ¥å‹ï¼‰

#### 3.2.1 Gymç’°å¢ƒã®å®Ÿè£…

**ã‚·ãƒŠãƒªã‚ª1_1å°‚ç”¨ç’°å¢ƒ**
```python
import gym
import numpy as np
from gym import spaces

class TradingEnvironment_Scenario_1_1(gym.Env):
    """
    ã‚·ãƒŠãƒªã‚ª1_1: ãƒˆãƒ¬ãƒ³ãƒ‰é€£ç¶šãƒ»é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯å°‚ç”¨ã®å–å¼•ç’°å¢ƒ
    """
    def __init__(self, data, initial_balance=100000):
        super().__init__()
        
        self.data = data
        self.initial_balance = initial_balance
        self.current_step = 0
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç©ºé–“: 0=Hold, 1=Buy_Small, 2=Buy_Medium, 3=Buy_Large, 
        #                 4=Close_Half, 5=Close_All, 6=Trailing_Stop
        self.action_space = spaces.Discrete(7)
        
        # è¦³æ¸¬ç©ºé–“: ã‚·ãƒŠãƒªã‚ª1_1ã«é–¢é€£ã™ã‚‹ç‰¹å¾´é‡
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, 
            shape=(25,),  # ç‰¹å¾´é‡ã®æ•°
            dtype=np.float32
        )
        
        self.reset()
    
    def reset(self):
        """ç’°å¢ƒã®ãƒªã‚»ãƒƒãƒˆ"""
        self.current_step = 100  # ååˆ†ãªå±¥æ­´ã‚’ç¢ºä¿
        self.balance = self.initial_balance
        self.position = None
        self.total_trades = 0
        self.winning_trades = 0
        
        return self._get_observation()
    
    def _get_observation(self):
        """ç¾åœ¨ã®è¦³æ¸¬ã‚’å–å¾—"""
        current_data = self.data.iloc[self.current_step]
        
        obs = np.array([
            # ä¾¡æ ¼æƒ…å ±
            current_data['close'],
            current_data['high'],
            current_data['low'],
            current_data['volume'],
            
            # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™
            current_data['ema9'],
            current_data['ema21'],
            current_data['ema200'],
            current_data['macd'],
            current_data['macd_signal'],
            current_data['rsi'],
            current_data['atr'],
            current_data['adx'],
            
            # ã‚·ãƒŠãƒªã‚ª1_1å›ºæœ‰ã®ç‰¹å¾´é‡
            current_data['breakout_strength'],  # ãƒ–ãƒ¬ã‚¤ã‚¯ã®å¼·ã•
            current_data['n_wave_ratio'],       # Næ³¢å‹•æ¯”ç‡
            current_data['ema9_distance'],      # EMA9ã¨ã®è·é›¢
            current_data['higher_high_count'],  # é«˜å€¤æ›´æ–°å›æ•°
            current_data['dow_trend'],          # ãƒ€ã‚¦ç†è«–ãƒˆãƒ¬ãƒ³ãƒ‰
            
            # ãƒã‚¸ã‚·ãƒ§ãƒ³æƒ…å ±
            1.0 if self.position else 0.0,
            self.position['size'] if self.position else 0.0,
            self.position['entry_price'] if self.position else 0.0,
            self.position['unrealized_pnl'] if self.position else 0.0,
            self.position['holding_bars'] if self.position else 0.0,
            
            # å£åº§æƒ…å ±
            self.balance,
            self.balance / self.initial_balance,  # ãƒªã‚¿ãƒ¼ãƒ³
            self.total_trades,
            self.winning_trades / max(1, self.total_trades)  # å‹ç‡
        ], dtype=np.float32)
        
        return obs
    
    def step(self, action):
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        current_price = self.data.iloc[self.current_step]['close']
        atr = self.data.iloc[self.current_step]['atr']
        
        reward = 0
        done = False
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        if action == 1:  # Buy Small
            if not self.position:
                self.position = {
                    'entry_price': current_price,
                    'size': 0.01,  # å°ãƒ­ãƒƒãƒˆ
                    'entry_step': self.current_step,
                    'stop_loss': current_price - 2 * atr,
                    'take_profit': current_price + 4 * atr
                }
        
        elif action == 2:  # Buy Medium
            if not self.position:
                self.position = {
                    'entry_price': current_price,
                    'size': 0.02,  # ä¸­ãƒ­ãƒƒãƒˆ
                    'entry_step': self.current_step,
                    'stop_loss': current_price - 2 * atr,
                    'take_profit': current_price + 4 * atr
                }
        
        elif action == 3:  # Buy Large
            if not self.position:
                self.position = {
                    'entry_price': current_price,
                    'size': 0.03,  # å¤§ãƒ­ãƒƒãƒˆ
                    'entry_step': self.current_step,
                    'stop_loss': current_price - 2 * atr,
                    'take_profit': current_price + 4 * atr
                }
        
        elif action == 4:  # Close Half
            if self.position:
                pnl = (current_price - self.position['entry_price']) * self.position['size'] * 0.5
                self.balance += pnl
                self.position['size'] *= 0.5
                reward += pnl * 10
        
        elif action == 5:  # Close All
            if self.position:
                pnl = (current_price - self.position['entry_price']) * self.position['size']
                self.balance += pnl
                self.total_trades += 1
                if pnl > 0:
                    self.winning_trades += 1
                    reward += pnl * 10 + 5  # å‹ã¡ãƒˆãƒ¬ãƒ¼ãƒ‰ãƒœãƒ¼ãƒŠã‚¹
                else:
                    reward += pnl * 10  # è² ã‘ã¯ãã®ã¾ã¾åæ˜ 
                self.position = None
        
        # ãƒã‚¸ã‚·ãƒ§ãƒ³ç®¡ç†
        if self.position:
            self.position['holding_bars'] = self.current_step - self.position['entry_step']
            self.position['unrealized_pnl'] = (current_price - self.position['entry_price']) * self.position['size']
            
            # ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ãƒ»ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆã®ãƒã‚§ãƒƒã‚¯
            if current_price <= self.position['stop_loss']:
                pnl = -2 * atr * self.position['size']
                self.balance += pnl
                self.total_trades += 1
                reward += pnl * 10  # æå¤±
                self.position = None
            
            elif current_price >= self.position['take_profit']:
                pnl = 4 * atr * self.position['size']
                self.balance += pnl
                self.total_trades += 1
                self.winning_trades += 1
                reward += pnl * 10 + 10  # å¤§ããªãƒœãƒ¼ãƒŠã‚¹
                self.position = None
        
        # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸
        self.current_step += 1
        
        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†åˆ¤å®š
        if self.current_step >= len(self.data) - 1:
            done = True
        
        if self.balance < self.initial_balance * 0.5:  # 50%ä»¥ä¸Šã®æå¤±
            done = True
            reward -= 100  # å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£
        
        obs = self._get_observation()
        info = {
            'balance': self.balance,
            'total_trades': self.total_trades,
            'win_rate': self.winning_trades / max(1, self.total_trades)
        }
        
        return obs, reward, done, info


class TradingEnvironment_Scenario_1_2(gym.Env):
    """
    ã‚·ãƒŠãƒªã‚ª1_2: ãƒˆãƒ¬ãƒ³ãƒ‰é€£ç¶šãƒ»æŠ¼ã—ç›®ç‹™ã„å°‚ç”¨ã®å–å¼•ç’°å¢ƒ
    """
    def __init__(self, data, initial_balance=100000):
        super().__init__()
        
        self.data = data
        self.initial_balance = initial_balance
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç©ºé–“: æŠ¼ã—ç›®ã«ç‰¹åŒ–ã—ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        # 0=Hold, 1=Buy_at_Fib_382, 2=Buy_at_Fib_500, 3=Buy_at_Fib_618,
        # 4=Close_Half, 5=Close_All
        self.action_space = spaces.Discrete(6)
        
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, 
            shape=(25,),
            dtype=np.float32
        )
        
        self.reset()
    
    def reset(self):
        self.current_step = 100
        self.balance = self.initial_balance
        self.position = None
        self.total_trades = 0
        self.winning_trades = 0
        return self._get_observation()
    
    def _get_observation(self):
        """ã‚·ãƒŠãƒªã‚ª1_2å›ºæœ‰ã®è¦³æ¸¬"""
        current_data = self.data.iloc[self.current_step]
        
        obs = np.array([
            # åŸºæœ¬æƒ…å ±
            current_data['close'],
            current_data['high'],
            current_data['low'],
            
            # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™
            current_data['ema9'],
            current_data['ema21'],
            current_data['macd'],
            current_data['rsi'],
            current_data['atr'],
            
            # ã‚·ãƒŠãƒªã‚ª1_2å›ºæœ‰ã®ç‰¹å¾´é‡
            current_data['fib_382_distance'],   # ãƒ•ã‚£ãƒœãƒŠãƒƒãƒ38.2%ã¾ã§ã®è·é›¢
            current_data['fib_500_distance'],   # ãƒ•ã‚£ãƒœãƒŠãƒƒãƒ50%ã¾ã§ã®è·é›¢
            current_data['fib_618_distance'],   # ãƒ•ã‚£ãƒœãƒŠãƒƒãƒ61.8%ã¾ã§ã®è·é›¢
            current_data['pullback_depth'],     # æŠ¼ã—ç›®ã®æ·±ã•
            current_data['n_wave_phase'],       # Næ³¢å‹•ã®ãƒ•ã‚§ãƒ¼ã‚º
            current_data['dow_trend'],          # ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘
            current_data['swing_low'],          # ã‚¹ã‚¤ãƒ³ã‚°ãƒ­ãƒ¼
            
            # ãƒã‚¸ã‚·ãƒ§ãƒ³æƒ…å ±ï¼ˆçœç•¥: å‰è¿°ã¨åŒæ§˜ï¼‰
            # ...
        ], dtype=np.float32)
        
        return obs
    
    def step(self, action):
        """æŠ¼ã—ç›®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã«ç‰¹åŒ–ã—ãŸã‚¹ãƒ†ãƒƒãƒ—å‡¦ç†"""
        # å®Ÿè£…ã¯çœç•¥ï¼ˆã‚·ãƒŠãƒªã‚ª1_1ã¨åŒæ§˜ã®æ§‹é€ ï¼‰
        pass


# ä»–ã®ã‚·ãƒŠãƒªã‚ªã‚‚åŒæ§˜ã«å®Ÿè£…
class TradingEnvironment_Scenario_2_1(gym.Env):
    """ã‚·ãƒŠãƒªã‚ª2_1: ãƒ¬ãƒ³ã‚¸ãƒ–ãƒ¬ã‚¤ã‚¯å°‚ç”¨ç’°å¢ƒ"""
    pass

class TradingEnvironment_Scenario_2_2(gym.Env):
    """ã‚·ãƒŠãƒªã‚ª2_2: ã‚µãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³ãƒ–ãƒ¬ã‚¤ã‚¯å°‚ç”¨ç’°å¢ƒ"""
    pass

class TradingEnvironment_Scenario_3_1(gym.Env):
    """ã‚·ãƒŠãƒªã‚ª3_1: ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ–ãƒ¬ã‚¤ã‚¯å°‚ç”¨ç’°å¢ƒ"""
    pass

class TradingEnvironment_Scenario_3_2(gym.Env):
    """ã‚·ãƒŠãƒªã‚ª3_2: ãƒãƒ£ãƒãƒ«å†…ã‚µãƒãƒ¼ãƒˆå°‚ç”¨ç’°å¢ƒ"""
    pass

class TradingEnvironment_Scenario_3_3(gym.Env):
    """ã‚·ãƒŠãƒªã‚ª3_3: ãƒ¬ãƒ³ã‚¸å†…ã‚µãƒãƒ¼ãƒˆå°‚ç”¨ç’°å¢ƒ"""
    pass
```

**å®Ÿè£…ã‚¿ã‚¹ã‚¯**
- [ ] ã‚·ãƒŠãƒªã‚ª1_1ç’°å¢ƒã®å®Œå…¨å®Ÿè£…ã¨ãƒ†ã‚¹ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª1_2ç’°å¢ƒã®å®Œå…¨å®Ÿè£…ã¨ãƒ†ã‚¹ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª2_1ç’°å¢ƒã®å®Œå…¨å®Ÿè£…ã¨ãƒ†ã‚¹ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª2_2ç’°å¢ƒã®å®Œå…¨å®Ÿè£…ã¨ãƒ†ã‚¹ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª3_1ç’°å¢ƒã®å®Œå…¨å®Ÿè£…ã¨ãƒ†ã‚¹ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª3_2ç’°å¢ƒã®å®Œå…¨å®Ÿè£…ã¨ãƒ†ã‚¹ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª3_3ç’°å¢ƒã®å®Œå…¨å®Ÿè£…ã¨ãƒ†ã‚¹ãƒˆ
- [ ] å„ç’°å¢ƒã®å‹•ä½œç¢ºèªï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã§ãƒ†ã‚¹ãƒˆï¼‰

### 3.3 XGBoostãƒ™ãƒ¼ã‚¹å¼·åŒ–å­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè£…

**é‡è¦**: æ·±å±¤å­¦ç¿’ï¼ˆDQN, PPOï¼‰ã§ã¯ãªãã€**XGBoostã‚’ä½¿ã£ãŸå¼·åŒ–å­¦ç¿’**ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

#### 3.3.1 XGBoost Q-Learningå®Ÿè£…
- [ ] ãƒ€ã‚¦ç†è«–è»¢æ›ã®ç¢ºèªæœ¬æ•°
- [ ] EMA9ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ã®åˆ¤å®šåŸºæº–
- [ ] MACDç¢ºèªã®æ„Ÿåº¦
- [ ] ã‚µãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³åè»¢ã®åˆ¤å®šæ¡ä»¶
- [ ] ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ä½ç½®ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ or ã‚µãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³ï¼‰
- [ ] åˆ©ç¢ºç›®æ¨™ï¼ˆå‰å›é«˜å€¤ or Næ³¢å‹•ï¼‰

**ã‚·ãƒŠãƒªã‚ª3_2: ãƒãƒ£ãƒãƒ«å†…ã‚µãƒãƒ¼ãƒˆ**
- [ ] ãƒãƒ£ãƒãƒ«æ¤œå‡ºã®ä¿¡é ¼åº¦é–¾å€¤
- [ ] ãƒãƒ£ãƒãƒ«ä¸‹é™åç™ºã®åˆ¤å®šåŸºæº–
- [ ] ãƒ•ã‚£ãƒœãƒŠãƒƒãƒãƒ¬ãƒ™ãƒ«ã®å„ªå…ˆåº¦
- [ ] ãƒ€ã‚¦ç†è«–å†…éƒ¨ãƒˆãƒ¬ãƒ³ãƒ‰ã®é‡ã¿
- [ ] ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼ˆåç™ºç›´å¾Œ or ç¢ºèªå¾Œï¼‰
- [ ] ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹å¹…ï¼ˆãƒãƒ£ãƒãƒ«ä¸‹é™ã‹ã‚‰ã®è·é›¢ï¼‰
- [ ] åˆ©ç¢ºç›®æ¨™ï¼ˆãƒãƒ£ãƒãƒ«ä¸Šé™ or ä¸­é–“ãƒ©ã‚¤ãƒ³ï¼‰

**ã‚·ãƒŠãƒªã‚ª3_3: ãƒ¬ãƒ³ã‚¸å†…ã‚µãƒãƒ¼ãƒˆ**
- [ ] ãƒ¬ãƒ³ã‚¸åˆ¤å®šã®æœ€å°ç¶™ç¶šæœŸé–“
- [ ] ãƒ¬ãƒ³ã‚¸ä¸‹é™åç™ºã®åˆ¤å®šåŸºæº–
- [ ] ãƒ•ã‚£ãƒœãƒŠãƒƒãƒã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®è¨±å®¹èª¤å·®
- [ ] ãƒ€ã‚¦ç†è«–å°æ³¢å‹•ã®é‡è¦åº¦
- [ ] ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä½ç½®ï¼ˆãƒ¬ãƒ³ã‚¸ä¸‹é™ã‹ã‚‰ã®%ï¼‰
- [ ] ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹å¹…ï¼ˆãƒ¬ãƒ³ã‚¸å¹…ã®ä½•%ï¼Ÿï¼‰
- [ ] åˆ©ç¢ºç›®æ¨™ï¼ˆãƒ¬ãƒ³ã‚¸ä¸Šé™ or ãƒ¬ãƒ³ã‚¸ä¸­å¤®ï¼‰

**ãã®ä»–ã‚·ãƒŠãƒªã‚ªï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ–ãƒ¬ã‚¤ã‚¯ã€ãƒãƒ£ãƒãƒ«å†…ã€ãƒ¬ãƒ³ã‚¸å†…ï¼‰**
- [ ] å„ã‚·ãƒŠãƒªã‚ªå›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©

#### å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå…¨ã‚·ãƒŠãƒªã‚ªã§èª¿æ•´å¯èƒ½ï¼‰
- [ ] ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºï¼ˆè³‡é‡‘ã®ä½•%ï¼Ÿï¼‰
- [ ] æœ€å¤§ä¿æœ‰æ™‚é–“
- [ ] ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ã®é–‹å§‹æ¡ä»¶
- [ ] éƒ¨åˆ†åˆ©ç¢ºã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°

### 3.3 XGBoostãƒ™ãƒ¼ã‚¹Q-Learningã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè£…ï¼ˆ7-10æ—¥ï¼‰

**é‡è¦**: æ·±å±¤å­¦ç¿’ï¼ˆDQN, PPOï¼‰ã§ã¯ãªãã€**XGBoostã‚’ä½¿ã£ãŸå¼·åŒ–å­¦ç¿’**ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

**ã‚¯ãƒ©ã‚¹ã‚¿å¯¾å¿œ**: å„ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«ç‹¬ç«‹ã—ãŸQ-Learningã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´ã—ã¾ã™ã€‚

#### 3.3.1 ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥XGBoost Q-Learningå®Ÿè£…

```python
# src/rl/xgboost_qlearning.py
import xgboost as xgb
import numpy as np
from collections import deque
import random
import joblib

class ClusterXGBoostQLearningAgent:
    """
    XGBoostã‚’ä½¿ã£ãŸQ-Learning ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆã‚¯ãƒ©ã‚¹ã‚¿å¯¾å¿œï¼‰
    
    å„ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«ç‹¬ç«‹ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã€‚
    çŠ¶æ…‹ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å…¥åŠ›ã¨ã—ã¦ã€Qå€¤ã‚’äºˆæ¸¬ã™ã‚‹XGBoostãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã€‚
    """
    def __init__(self, cluster_id, cluster_name, n_actions, n_features):
        self.cluster_id = cluster_id
        self.cluster_name = cluster_name
        self.n_actions = n_actions
        self.n_features = n_features
        
        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.gamma = 0.95  # å‰²å¼•ç‡
        self.epsilon = 1.0  # æ¢ç´¢ç‡ï¼ˆåˆæœŸå€¤100%ï¼‰
        self.epsilon_min = 0.05  # æœ€å°æ¢ç´¢ç‡
        self.epsilon_decay = 0.995  # æ¢ç´¢ç‡æ¸›è¡°
        self.learning_rate = 0.1
        
        # çµŒé¨“ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡
        self.memory = deque(maxlen=10000)
        self.batch_size = 64
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ¥XGBoostãƒ¢ãƒ‡ãƒ«ï¼ˆå„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«Qå€¤ã‚’äºˆæ¸¬ï¼‰
        self.q_models = {}
        for action in range(n_actions):
            self.q_models[action] = xgb.XGBRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                objective='reg:squarederror',
                random_state=42
            )
        
        self.trained = False
        self.training_history = []
    
    def get_action(self, state, training=True):
        """
        Îµ-greedyæ³•ã§ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠ
        
        Args:
            state: ç¾åœ¨ã®çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«
            training: è¨“ç·´ä¸­ã‹ã©ã†ã‹
        
        Returns:
            é¸æŠã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        """
        # æ¢ç´¢ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
        if training and np.random.rand() <= self.epsilon:
            return np.random.randint(0, self.n_actions)
        
        # æ´»ç”¨ï¼ˆæœ€å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
        if self.trained:
            q_values = self.predict_q_values(state)
            return np.argmax(q_values)
        else:
            # æœªè¨“ç·´ã®å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ 
            return np.random.randint(0, self.n_actions)
    
    def predict_q_values(self, state):
        """
        å…¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®Qå€¤ã‚’äºˆæ¸¬
        
        Returns:
            å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®Qå€¤é…åˆ—
        """
        q_values = []
        state = state.reshape(1, -1)
        
        for action in range(self.n_actions):
            if self.trained:
                q_val = self.q_models[action].predict(state)[0]
            else:
                q_val = 0.0
            q_values.append(q_val)
        
        return np.array(q_values)
    
    def remember(self, state, action, reward, next_state, done):
        """çµŒé¨“ã‚’è¨˜æ†¶"""
        self.memory.append((state, action, reward, next_state, done))
    
    def replay(self):
        """
        çµŒé¨“ãƒªãƒ—ãƒ¬ã‚¤ã«ã‚ˆã‚‹å­¦ç¿’
        
        ãƒ¡ãƒ¢ãƒªã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒãƒƒãƒã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€
        å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®Qå€¤ã‚’æ›´æ–°
        """
        if len(self.memory) < self.batch_size:
            return
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        minibatch = random.sample(self.memory, self.batch_size)
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é›¢
        action_data = {a: {'X': [], 'y': []} for a in range(self.n_actions)}
        
        for state, action, reward, next_state, done in minibatch:
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆQå€¤ã®è¨ˆç®—
            if done:
                target = reward
            else:
                # Bellmanæ–¹ç¨‹å¼: Q(s,a) = r + Î³ * max(Q(s',a'))
                next_q_values = self.predict_q_values(next_state)
                target = reward + self.gamma * np.max(next_q_values)
            
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            action_data[action]['X'].append(state)
            action_data[action]['y'].append(target)
        
        # å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
        for action in range(self.n_actions):
            if len(action_data[action]['X']) > 0:
                X = np.array(action_data[action]['X'])
                y = np.array(action_data[action]['y'])
                
                # ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«å­¦ç¿’ï¼ˆXGBoostã®xgb_modelå¼•æ•°ã‚’ä½¿ç”¨ï¼‰
                if self.trained:
                    self.q_models[action].fit(
                        X, y,
                        xgb_model=self.q_models[action].get_booster()
                    )
                else:
                    self.q_models[action].fit(X, y)
        
        # Îµã‚’æ¸›è¡°
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay
        
        self.trained = True
    
    def train(self, env, n_episodes=1000, verbose=True):
        """
        ç’°å¢ƒã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´
        
        Args:
            env: ClusterTradingEnvironment
            n_episodes: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°
            verbose: é€²æ—è¡¨ç¤º
        
        Returns:
            è¨“ç·´å±¥æ­´
        """
        print(f"\n{'='*60}")
        print(f"ã‚¯ãƒ©ã‚¹ã‚¿ {self.cluster_id} ({self.cluster_name}) ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨“ç·´é–‹å§‹")
        print(f"{'='*60}")
        
        for episode in range(n_episodes):
            state = env.reset()
            total_reward = 0
            done = False
            step = 0
            
            while not done:
                # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³é¸æŠ
                action = self.get_action(state, training=True)
                
                # ç’°å¢ƒã§ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
                next_state, reward, done, info = env.step(action)
                
                # çµŒé¨“ã‚’è¨˜æ†¶
                self.remember(state, action, reward, next_state, done)
                
                # å­¦ç¿’
                if len(self.memory) >= self.batch_size:
                    self.replay()
                
                state = next_state
                total_reward += reward
                step += 1
            
            self.training_history.append({
                'episode': episode,
                'total_reward': total_reward,
                'epsilon': self.epsilon,
                'balance': info['balance'],
                'trades': info['trades']
            })
            
            # é€²æ—è¡¨ç¤º
            if verbose and (episode + 1) % 100 == 0:
                avg_reward = np.mean([h['total_reward'] for h in self.training_history[-100:]])
                avg_balance = np.mean([h['balance'] for h in self.training_history[-100:]])
                print(f"ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {episode+1}/{n_episodes} - "
                      f"å¹³å‡å ±é…¬: {avg_reward:.2f}, "
                      f"å¹³å‡æ®‹é«˜: {avg_balance:.2f}, "
                      f"Îµ: {self.epsilon:.3f}")
        
        print(f"âœ“ è¨“ç·´å®Œäº†")
        return self.training_history
    
    def save(self, filepath):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¿å­˜"""
        save_data = {
            'cluster_id': self.cluster_id,
            'cluster_name': self.cluster_name,
            'n_actions': self.n_actions,
            'n_features': self.n_features,
            'q_models': self.q_models,
            'epsilon': self.epsilon,
            'training_history': self.training_history,
            'trained': self.trained
        }
        joblib.dump(save_data, filepath)
        print(f"âœ“ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¿å­˜: {filepath}")
    
    @classmethod
    def load(cls, filepath):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿"""
        save_data = joblib.load(filepath)
        
        agent = cls(
            save_data['cluster_id'],
            save_data['cluster_name'],
            save_data['n_actions'],
            save_data['n_features']
        )
        agent.q_models = save_data['q_models']
        agent.epsilon = save_data['epsilon']
        agent.training_history = save_data['training_history']
        agent.trained = save_data['trained']
        
        print(f"âœ“ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿: {filepath}")
        return agent
```

#### 3.3.2 å…¨ã‚¯ãƒ©ã‚¹ã‚¿ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨“ç·´

```python
# scripts/train_cluster_agents.py
"""
å…¨ã‚¯ãƒ©ã‚¹ã‚¿ã®RL ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¸¦è¡Œè¨“ç·´
"""
from src.rl.xgboost_qlearning import ClusterXGBoostQLearningAgent
from src.rl.trading_environment import ClusterTradingEnvironment
from src.clustering.market_regime_detector import MarketRegimeDetector
import json

def train_all_cluster_agents(data, detector, cluster_labels, n_episodes=1000):
    """
    ã™ã¹ã¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰å¯èƒ½ã‚¯ãƒ©ã‚¹ã‚¿ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´
    """
    print("\n" + "="*60)
    print("å…¨ã‚¯ãƒ©ã‚¹ã‚¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨“ç·´")
    print("="*60)
    
    agents = {}
    training_results = {}
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‰å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã‚¿ã‚’å–å¾—
    tradeable_clusters = [
        cid for cid in range(detector.n_clusters)
        if len(data[data['cluster'] == cid]) >= 100
    ]
    
    print(f"è¨“ç·´å¯¾è±¡ã‚¯ãƒ©ã‚¹ã‚¿: {tradeable_clusters}")
    
    for cluster_id in tradeable_clusters:
        cluster_name = cluster_labels.get(cluster_id, f"Cluster_{cluster_id}")
        
        try:
            # ç’°å¢ƒä½œæˆ
            env = ClusterTradingEnvironment(
                data=data,
                cluster_id=cluster_id,
                cluster_labels=cluster_labels,
                initial_balance=100000,
                commission=0.002
            )
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
            agent = ClusterXGBoostQLearningAgent(
                cluster_id=cluster_id,
                cluster_name=cluster_name,
                n_actions=7,
                n_features=STATE_SIZE
            )
            
            # è¨“ç·´
            history = agent.train(env, n_episodes=n_episodes, verbose=True)
            
            # ä¿å­˜
            agent.save(f'models/layer2/agent_cluster_{cluster_id}.pkl')
            
            agents[cluster_id] = agent
            training_results[cluster_id] = history
            
        except Exception as e:
            print(f"âœ— ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id} ã®è¨“ç·´ã«å¤±æ•—: {e}")
            continue
    
    # çµæœã‚’JSONä¿å­˜
    with open('outputs/cluster_agents_training_results.json', 'w') as f:
        json.dump(training_results, f, indent=2)
    
    print(f"\nâœ“ {len(agents)}å€‹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨“ç·´å®Œäº†")
    return agents, training_results

# å®Ÿè¡Œ
if __name__ == "__main__":
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data = pd.read_csv('data/processed/features_with_clusters.csv')
    
    # ã‚¯ãƒ©ã‚¹ã‚¿æ¤œå‡ºå™¨èª­ã¿è¾¼ã¿
    detector = MarketRegimeDetector()
    detector.load('models/layer1/market_regime_detector.pkl')
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒ«èª­ã¿è¾¼ã¿
    with open('config/cluster_labels.json', 'r', encoding='utf-8') as f:
        cluster_labels = json.load(f)
    
    # è¨“ç·´å®Ÿè¡Œ
    agents, results = train_all_cluster_agents(
        data, 
        detector, 
        cluster_labels, 
        n_episodes=1000
    )
```

**ä½œæ¥­ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
- [ ] ClusterXGBoostQLearningAgentã‚¯ãƒ©ã‚¹ã‚’å®Ÿè£…
- [ ] å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ç’°å¢ƒã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´
- [ ] è¨“ç·´å±¥æ­´ã‚’ã‚°ãƒ©ãƒ•ã§ç¢ºèª
- [ ] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’models/layer2/ã«ä¿å­˜

---

### 3.4 ã€å‚è€ƒã€‘ã‚·ãƒŠãƒªã‚ªåˆ¥XGBoost Q-Learningï¼ˆå¾“æ¥å‹ï¼‰

ä»¥ä¸‹ã¯å¾“æ¥ã®ã‚·ãƒŠãƒªã‚ªãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã™ã€‚

#### 3.4.1 ã€å‚è€ƒã€‘ã‚·ãƒŠãƒªã‚ªåˆ¥å®Ÿè£…

```python
# å¾“æ¥å‹ï¼ˆå‚è€ƒï¼‰
class XGBoostQLearningAgent:
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.learning_rate = 0.1
        
        # çµŒé¨“ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡
        self.memory = deque(maxlen=10000)
        self.batch_size = 64
        
        # å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾ã™ã‚‹XGBoostãƒ¢ãƒ‡ãƒ«
        self.models = {}
        for action in range(n_actions):
            self.models[action] = xgb.XGBRegressor(
                objective='reg:squarederror',
                n_estimators=100,
                max_depth=5,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                tree_method='hist'
            )
        
        # åˆæœŸåŒ–ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´
        self._initialize_models()
    
    def _initialize_models(self):
        """ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–"""
        X_init = np.random.random((100, self.n_features))
        y_init = np.zeros(100)
        
        for action in range(self.n_actions):
            self.models[action].fit(X_init, y_init)
    
    def remember(self, state, action, reward, next_state, done):
        """çµŒé¨“ã‚’è¨˜æ†¶"""
        self.memory.append((state, action, reward, next_state, done))
    
    def act(self, state):
        """è¡Œå‹•é¸æŠï¼ˆÎµ-greedyï¼‰"""
        if np.random.random() <= self.epsilon:
            return random.randrange(self.n_actions)  # ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        
        # å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®Qå€¤ã‚’äºˆæ¸¬
        q_values = []
        for action in range(self.n_actions):
            q_value = self.models[action].predict(state.reshape(1, -1))[0]
            q_values.append(q_value)
        
        return np.argmax(q_values)  # æœ€å¤§Qå€¤ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    
    def replay(self):
        """çµŒé¨“ãƒªãƒ—ãƒ¬ã‚¤ã§å­¦ç¿’"""
        if len(self.memory) < self.batch_size:
            return
        
        # ãƒŸãƒ‹ãƒãƒƒãƒã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        minibatch = random.sample(self.memory, self.batch_size)
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é¡
        training_data = {action: {'X': [], 'y': []} for action in range(self.n_actions)}
        
        for state, action, reward, next_state, done in minibatch:
            if done:
                target = reward
            else:
                # æ¬¡çŠ¶æ…‹ã®æœ€å¤§Qå€¤ã‚’å–å¾—
                next_q_values = []
                for a in range(self.n_actions):
                    next_q = self.models[a].predict(next_state.reshape(1, -1))[0]
                    next_q_values.append(next_q)
                
                target = reward + self.gamma * np.max(next_q_values)
            
            training_data[action]['X'].append(state)
            training_data[action]['y'].append(target)
        
        # å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
        for action in range(self.n_actions):
            if len(training_data[action]['X']) > 0:
                X = np.array(training_data[action]['X'])
                y = np.array(training_data[action]['y'])
                
                # XGBoostãƒ¢ãƒ‡ãƒ«ã®å¢—åˆ†å­¦ç¿’ï¼ˆxgb_modelã§ç¶™ç¶šå­¦ç¿’ï¼‰
                self.models[action].fit(
                    X, y,
                    xgb_model=self.models[action].get_booster()
                )
        
        # æ¢ç´¢ç‡ã‚’æ¸›è¡°
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay
    
    def save(self, filepath):
        """ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜"""
        for action in range(self.n_actions):
            self.models[action].save_model(f"{filepath}_action_{action}.json")
    
    def load(self, filepath):
        """ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        for action in range(self.n_actions):
            self.models[action].load_model(f"{filepath}_action_{action}.json")


# ã‚·ãƒŠãƒªã‚ªã”ã¨ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
def create_agent_for_scenario(scenario_id):
    """
    ã‚·ãƒŠãƒªã‚ªã”ã¨ã«é©åˆ‡ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°ã¨ç‰¹å¾´é‡æ•°ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    """
    agent_configs = {
        '1_1': {'n_actions': 7, 'n_features': 25},  # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ
        '1_2': {'n_actions': 6, 'n_features': 25},  # æŠ¼ã—ç›®
        '2_1': {'n_actions': 7, 'n_features': 25},  # ãƒ¬ãƒ³ã‚¸ãƒ–ãƒ¬ã‚¤ã‚¯
        '2_2': {'n_actions': 6, 'n_features': 23},  # ã‚µãƒãƒ¼ãƒˆãƒ–ãƒ¬ã‚¤ã‚¯
        '3_1': {'n_actions': 7, 'n_features': 26},  # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ–ãƒ¬ã‚¤ã‚¯
        '3_2': {'n_actions': 6, 'n_features': 24},  # ãƒãƒ£ãƒãƒ«
        '3_3': {'n_actions': 6, 'n_features': 24},  # ãƒ¬ãƒ³ã‚¸å†…
    }
    
    config = agent_configs[scenario_id]
    return XGBoostQLearningAgent(
        scenario_id=scenario_id,
        n_actions=config['n_actions'],
        n_features=config['n_features']
    )
```

#### 3.3.2 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´

```python
def train_agent(agent, env, episodes=1000):
    """
    XGBoost Q-Learningã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´
    """
    episode_rewards = []
    episode_trades = []
    
    for episode in range(episodes):
        state = env.reset()
        total_reward = 0
        done = False
        step = 0
        
        while not done:
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³é¸æŠ
            action = agent.act(state)
            
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            next_state, reward, done, info = env.step(action)
            
            # çµŒé¨“ã‚’è¨˜æ†¶
            agent.remember(state, action, reward, next_state, done)
            
            state = next_state
            total_reward += reward
            step += 1
            
            # çµŒé¨“ãƒªãƒ—ãƒ¬ã‚¤ã§å­¦ç¿’
            if step % 10 == 0:  # 10ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«å­¦ç¿’
                agent.replay()
        
        episode_rewards.append(total_reward)
        episode_trades.append(info['total_trades'])
        
        # é€²æ—è¡¨ç¤º
        if episode % 50 == 0:
            avg_reward = np.mean(episode_rewards[-50:])
            avg_trades = np.mean(episode_trades[-50:])
            print(f"Episode: {episode}, Avg Reward: {avg_reward:.2f}, "
                  f"Avg Trades: {avg_trades:.1f}, Epsilon: {agent.epsilon:.3f}, "
                  f"Win Rate: {info['win_rate']:.2%}")
    
    return episode_rewards

# å„ã‚·ãƒŠãƒªã‚ªã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´
scenarios = ['1_1', '1_2', '2_1', '2_2', '3_1', '3_2', '3_3']

for scenario_id in scenarios:
    print(f"\n========== Training Agent for Scenario {scenario_id} ==========")
    
    # ç’°å¢ƒã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆ
    if scenario_id == '1_1':
        env = TradingEnvironment_Scenario_1_1(train_data)
    elif scenario_id == '1_2':
        env = TradingEnvironment_Scenario_1_2(train_data)
    # ä»–ã®ã‚·ãƒŠãƒªã‚ªã‚‚åŒæ§˜
    
    agent = create_agent_for_scenario(scenario_id)
    
    # è¨“ç·´å®Ÿè¡Œ
    rewards = train_agent(agent, env, episodes=1000)
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    agent.save(f'models/layer2/rl_agents/xgboost_agent_scenario_{scenario_id}')
    
    # å­¦ç¿’æ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆ
    plt.plot(rewards)
    plt.title(f'Scenario {scenario_id} - Learning Curve')
    plt.xlabel('Episode')
    plt.ylabel('Total Reward')
    plt.savefig(f'models/layer2/rl_agents/learning_curve_{scenario_id}.png')
    plt.close()
```

**å®Ÿè£…ã‚¿ã‚¹ã‚¯**
- [ ] XGBoost Q-Learningã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Œå…¨å®Ÿè£…
- [ ] ã‚·ãƒŠãƒªã‚ª1_1ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´ã¨è©•ä¾¡
- [ ] ã‚·ãƒŠãƒªã‚ª1_2ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´ã¨è©•ä¾¡
- [ ] ã‚·ãƒŠãƒªã‚ª2_1ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´ã¨è©•ä¾¡
- [ ] ã‚·ãƒŠãƒªã‚ª2_2ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´ã¨è©•ä¾¡
- [ ] ã‚·ãƒŠãƒªã‚ª3_1ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´ã¨è©•ä¾¡
- [ ] ã‚·ãƒŠãƒªã‚ª3_2ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´ã¨è©•ä¾¡
- [ ] ã‚·ãƒŠãƒªã‚ª3_3ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´ã¨è©•ä¾¡
- [ ] å­¦ç¿’æ›²ç·šã®åˆ†æã¨æœ€é©åŒ–

#### 3.3.3 ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

```python
import optuna

def optimize_agent_hyperparameters(scenario_id, env, n_trials=100):
    """
    Optunaã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–
    """
    def objective(trial):
        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ææ¡ˆ
        gamma = trial.suggest_float('gamma', 0.9, 0.99)
        epsilon_decay = trial.suggest_float('epsilon_decay', 0.990, 0.999)
        batch_size = trial.suggest_int('batch_size', 32, 128)
        
        xgb_params = {
            'n_estimators': trial.suggest_int('n_estimators', 50, 200),
            'max_depth': trial.suggest_int('max_depth', 3, 8),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
            'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        }
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
        agent = create_agent_for_scenario(scenario_id)
        agent.gamma = gamma
        agent.epsilon_decay = epsilon_decay
        agent.batch_size = batch_size
        
        # XGBoostãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
        for action in range(agent.n_actions):
            agent.models[action] = xgb.XGBRegressor(**xgb_params, tree_method='hist')
            agent.models[action].fit(
                np.random.random((100, agent.n_features)),
                np.zeros(100)
            )
        
        # çŸ­æœŸé–“ã®è¨“ç·´
        rewards = train_agent(agent, env, episodes=100)
        
        # æœ€å¾Œ50ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®å¹³å‡å ±é…¬ã‚’è¿”ã™
        return np.mean(rewards[-50:])
    
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=n_trials)
    
    return study.best_params
```

- [ ] å„ã‚·ãƒŠãƒªã‚ªã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
- [ ] æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®å†è¨“ç·´

### 3.4 çµ±åˆã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆ3-4æ—¥ï¼‰

#### 3.4.1 Layer 2ï¼ˆå¼·åŒ–å­¦ç¿’ï¼‰ã®çµ±åˆå®Ÿè£…

**ã‚·ãƒŠãƒªã‚ªã”ã¨ã«ç‹¬ç«‹ã—ãŸæœ€é©åŒ–ã‚’å®Ÿè¡Œ**

```python
# ã‚·ãƒŠãƒªã‚ª1_1å°‚ç”¨ã®æœ€é©åŒ–
def optimize_scenario_1_1(historical_data):
    def objective(trial):
        params = {
            'breakout_threshold': trial.suggest_float('breakout_threshold', 1, 10),
            'n_wave_ratio': trial.suggest_categorical('n_wave_ratio', [1.0, 1.6, 2.0, 2.618]),
            'ema_distance': trial.suggest_int('ema_distance', 5, 50),
            'stop_loss_atr': trial.suggest_float('stop_loss_atr', 1.0, 3.0),
            'confirmation_bars': trial.suggest_int('confirmation_bars', 1, 5)
        }
        
        # ã‚·ãƒŠãƒªã‚ª1_1ã®ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ã§ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
        results = backtest_scenario_1_1(historical_data, params)
        return results['sharpe_ratio']
    
    study = optuna.create_study(direction='maximize', study_name='scenario_1_1')
    study.optimize(objective, n_trials=1000)
    return study.best_params

# ã‚·ãƒŠãƒªã‚ª1_2å°‚ç”¨ã®æœ€é©åŒ–
def optimize_scenario_1_2(historical_data):
    def objective(trial):
        params = {
            'fib_tolerance': trial.suggest_float('fib_tolerance', 1, 20),
            'max_wait_bars': trial.suggest_int('max_wait_bars', 3, 20),
            'entry_timing': trial.suggest_categorical('entry_timing', ['immediate', 'confirmation']),
            'stop_loss_type': trial.suggest_categorical('stop_loss_type', ['swing_low', 'fib_level']),
            'n_wave_weight': trial.suggest_float('n_wave_weight', 0.5, 1.5)
        }
        
        results = backtest_scenario_1_2(historical_data, params)
        return results['sharpe_ratio']
    
    study = optuna.create_study(direction='maximize', study_name='scenario_1_2')
    study.optimize(objective, n_trials=1000)
    return study.best_params

# ä»–ã®ã‚·ãƒŠãƒªã‚ªã‚‚åŒæ§˜ã«å®Ÿè£…
def optimize_scenario_2_1(historical_data): ...
def optimize_scenario_2_2(historical_data): ...
def optimize_scenario_3_1(historical_data): ...
def optimize_scenario_3_2(historical_data): ...
def optimize_scenario_3_3(historical_data): ...
```

**å®Ÿè£…ã‚¿ã‚¹ã‚¯**
- [ ] ã‚·ãƒŠãƒªã‚ª1_1ã®æœ€é©åŒ–é–¢æ•°ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª1_2ã®æœ€é©åŒ–é–¢æ•°ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª2_1ã®æœ€é©åŒ–é–¢æ•°ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª2_2ã®æœ€é©åŒ–é–¢æ•°ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª3_1ã®æœ€é©åŒ–é–¢æ•°ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª3_2ã®æœ€é©åŒ–é–¢æ•°ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª3_3ã®æœ€é©åŒ–é–¢æ•°ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
- [ ] å…¨ã‚·ãƒŠãƒªã‚ªã®æœ€é©åŒ–ã‚’ä¸€æ‹¬å®Ÿè¡Œã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### 3.2.2 ãƒãƒ«ãƒã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒ†ã‚£ãƒ–æœ€é©åŒ–ï¼ˆå¿œç”¨ï¼‰
- [ ] è¤‡æ•°æŒ‡æ¨™ã®åŒæ™‚æœ€é©åŒ–ï¼ˆã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª + æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ï¼‰
- [ ] ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã®å–å¾—
- [ ] ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•åˆ†æ

#### 3.2.3 ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰åˆ†æï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°é˜²æ­¢ï¼‰
```python
def walk_forward_optimization(data, scenario_id, n_splits=5):
    """
    æ™‚ç³»åˆ—ã‚’è€ƒæ…®ã—ãŸã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰åˆ†æ
    """
    results = []
    split_size = len(data) // (n_splits + 1)
    
    for i in range(n_splits):
        # è¨“ç·´æœŸé–“ã¨ãƒ†ã‚¹ãƒˆæœŸé–“ã‚’åˆ†å‰²
        train_start = 0
        train_end = split_size * (i + 1)
        test_start = train_end
        test_end = split_size * (i + 2)
        
        train_data = data[train_start:train_end]
        test_data = data[test_start:test_end]
        
        # è¨“ç·´æœŸé–“ã§æœ€é©åŒ–
        if scenario_id == '1_1':
            best_params = optimize_scenario_1_1(train_data)
        elif scenario_id == '1_2':
            best_params = optimize_scenario_1_2(train_data)
        elif scenario_id == '2_1':
            best_params = optimize_scenario_2_1(train_data)
        elif scenario_id == '2_2':
            best_params = optimize_scenario_2_2(train_data)
        elif scenario_id == '3_1':
            best_params = optimize_scenario_3_1(train_data)
        elif scenario_id == '3_2':
            best_params = optimize_scenario_3_2(train_data)
        elif scenario_id == '3_3':
            best_params = optimize_scenario_3_3(train_data)
        # ä»–ã®ã‚·ãƒŠãƒªã‚ªã‚‚åŒæ§˜
        
        # ãƒ†ã‚¹ãƒˆæœŸé–“ã§æ¤œè¨¼
        test_results = backtest_with_params(test_data, best_params, scenario_id)
        results.append(test_results)
    
    return results
```

- [ ] å„ã‚·ãƒŠãƒªã‚ªã®ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰åˆ†æå®Ÿè¡Œ
- [ ] å®‰å®šæ€§ã®è©•ä¾¡ï¼ˆæœŸé–“ã”ã¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å¤‰å‹•ï¼‰
- [ ] æœ€çµ‚çš„ãªæ¨å¥¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ±ºå®š

#### 3.2.4 å¸‚å ´ç’°å¢ƒé©å¿œå‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¿œç”¨ï¼‰
å„ã‚·ãƒŠãƒªã‚ªå†…ã§ã•ã‚‰ã«å¸‚å ´ç’°å¢ƒã«å¿œã˜ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‹•çš„èª¿æ•´

- [ ] ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡º
  - é«˜ãƒœãƒ©ç’°å¢ƒ: ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹åºƒã‚
  - ä½ãƒœãƒ©ç’°å¢ƒ: ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ç‹­ã‚

- [ ] ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
  - å¼·ãƒˆãƒ¬ãƒ³ãƒ‰: ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆé‡è¦–
  - å¼±ãƒˆãƒ¬ãƒ³ãƒ‰: æŠ¼ã—ç›®é‡è¦–

#### 3.2.5 æœ€é©åŒ–çµæœã®ä¿å­˜ï¼ˆé‡è¦ï¼‰
```python
# å„ã‚·ãƒŠãƒªã‚ªã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜
optimal_params = {
    'scenario_1_1': {
        'breakout_threshold': 3.5,
        'n_wave_ratio': 1.618,
        'ema_distance': 15,
        'stop_loss_atr': 2.0,
        'confirmation_bars': 2
    },
    'scenario_1_2': {
        'fib_tolerance': 8.0,
        'max_wait_bars': 10,
        'entry_timing': 'confirmation',
        'stop_loss_type': 'swing_low',
        'n_wave_weight': 1.2
    },
    'scenario_2_1': { ... },
    'scenario_2_2': { ... },
    'scenario_3_1': {
        'trendline_break_threshold': 5.0,
        'dow_confirmation_bars': 3,
        'ema9_reversal_threshold': 0.05,
        'macd_sensitivity': 'medium',
        'support_reversal_pips': 10,
        'stop_loss_type': 'trendline',
        'target_type': 'n_wave'
    },
    'scenario_3_2': {
        'channel_confidence': 0.8,
        'channel_support_threshold': 3.0,
        'fib_priority': 'high',
        'dow_internal_weight': 0.7,
        'entry_timing': 'confirmation',
        'stop_loss_distance': 10,
        'target_type': 'channel_upper'
    },
    'scenario_3_3': {
        'range_min_duration': 20,
        'range_support_threshold': 5.0,
        'fib_tolerance': 8.0,
        'dow_mini_wave_weight': 0.6,
        'entry_position_pct': 0.1,
        'stop_loss_pct': 0.05,
        'target_type': 'range_upper'
    }
}

# JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
import json
with open('models/layer2/optimal_params.json', 'w') as f:
    json.dump(optimal_params, f, indent=2)
```

- [ ] å„ã‚·ãƒŠãƒªã‚ªã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§ä¿å­˜
- [ ] ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
- [ ] ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¬æ˜ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ

### 3.3 ã‚¢ãƒ—ãƒ­ãƒ¼ãƒB: ã‚·ãƒŠãƒªã‚ªåˆ¥å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³/é«˜é›£åº¦ï¼‰

**å„ã‚·ãƒŠãƒªã‚ªã”ã¨ã«ç‹¬ç«‹ã—ãŸå¼·åŒ–å­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´**

#### 3.3.1 ã‚·ãƒŠãƒªã‚ªå°‚ç”¨ç’°å¢ƒã®æ§‹ç¯‰
```python
import gym
from stable_baselines3 import PPO

class TradingEnvironment_Scenario_1_1(gym.Env):
    """ã‚·ãƒŠãƒªã‚ª1_1å°‚ç”¨ã®å–å¼•ç’°å¢ƒ"""
    def __init__(self, data):
        # ã‚·ãƒŠãƒªã‚ª1_1ã«ç‰¹åŒ–ã—ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç©ºé–“
        self.action_space = gym.spaces.Discrete(4)  
        # 0: Hold, 1: Buy (aggressive), 2: Buy (conservative), 3: Close
        
        # ã‚·ãƒŠãƒªã‚ª1_1ã«é–¢é€£ã™ã‚‹è¦³æ¸¬ç©ºé–“
        self.observation_space = gym.spaces.Box(
            low=-np.inf, high=np.inf, 
            shape=(feature_dim,), dtype=np.float32
        )
        # ç‰¹å¾´é‡: ãƒ–ãƒ¬ã‚¤ã‚¯å¹…ã€Næ³¢å‹•æ¯”ç‡ã€EMAä¹–é›¢ç‡ãªã©
        
    def step(self, action):
        # ã‚·ãƒŠãƒªã‚ª1_1å›ºæœ‰ã®ãƒ­ã‚¸ãƒƒã‚¯ã§å ±é…¬è¨ˆç®—
        reward = self.calculate_scenario_1_1_reward(action)
        return observation, reward, done, info
    
    def reset(self):
        return initial_observation

class TradingEnvironment_Scenario_1_2(gym.Env):
    """ã‚·ãƒŠãƒªã‚ª1_2å°‚ç”¨ã®å–å¼•ç’°å¢ƒ"""
    def __init__(self, data):
        # ã‚·ãƒŠãƒªã‚ª1_2ã«ç‰¹åŒ–ã—ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç©ºé–“
        self.action_space = gym.spaces.Discrete(5)
        # 0: Wait, 1: Buy at Fib 38.2%, 2: Buy at Fib 50%, 
        # 3: Buy at Fib 61.8%, 4: Close
        
        self.observation_space = gym.spaces.Box(...)
        # ç‰¹å¾´é‡: ãƒ•ã‚£ãƒœãƒŠãƒƒãƒãƒ¬ãƒ™ãƒ«ã¾ã§ã®è·é›¢ã€æŠ¼ã—ç›®ã®æ·±ã•ãªã©
    
    def step(self, action):
        reward = self.calculate_scenario_1_2_reward(action)
        return observation, reward, done, info
    
    def reset(self):
        return initial_observation

# ä»–ã®ã‚·ãƒŠãƒªã‚ªã‚‚åŒæ§˜ã«å®Ÿè£…
```

#### 3.3.2 ã‚·ãƒŠãƒªã‚ªã”ã¨ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨“ç·´
```python
# ã‚·ãƒŠãƒªã‚ª1_1ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨“ç·´
env_1_1 = TradingEnvironment_Scenario_1_1(train_data_1_1)
model_1_1 = PPO('MlpPolicy', env_1_1, verbose=1)
model_1_1.learn(total_timesteps=100000)
model_1_1.save('models/layer2/rl_agent_scenario_1_1')

# ã‚·ãƒŠãƒªã‚ª1_2ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨“ç·´
env_1_2 = TradingEnvironment_Scenario_1_2(train_data_1_2)
model_1_2 = PPO('MlpPolicy', env_1_2, verbose=1)
model_1_2.learn(total_timesteps=100000)
model_1_2.save('models/layer2/rl_agent_scenario_1_2')

# ä»–ã®ã‚·ãƒŠãƒªã‚ªã‚‚åŒæ§˜ã«è¨“ç·´
```

#### 3.3.3 å ±é…¬é–¢æ•°ã®è¨­è¨ˆï¼ˆã‚·ãƒŠãƒªã‚ªã”ã¨ã«ç•°ãªã‚‹ï¼‰
- [ ] ã‚·ãƒŠãƒªã‚ª1_1ã®å ±é…¬é–¢æ•°
  - ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆæˆåŠŸæ™‚ã®ãƒœãƒ¼ãƒŠã‚¹
  - Næ³¢å‹•ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ°é”æ™‚ã®å¤§ããªå ±é…¬
  - ãƒ€ãƒã‚·ãƒ–ãƒ¬ã‚¤ã‚¯ã¸ã®ãƒšãƒŠãƒ«ãƒ†ã‚£

- [ ] ã‚·ãƒŠãƒªã‚ª1_2ã®å ±é…¬é–¢æ•°
  - ç†æƒ³çš„ãªãƒ•ã‚£ãƒœãƒŠãƒƒãƒãƒ¬ãƒ™ãƒ«ã§ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼å ±é…¬
  - æŠ¼ã—ç›®å½¢æˆç¢ºèªå¾Œã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒœãƒ¼ãƒŠã‚¹
  - æ—©ã™ãã‚‹ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã¸ã®ãƒšãƒŠãƒ«ãƒ†ã‚£

- [ ] å…±é€šã®å ±é…¬è¦ç´ 
  - åˆ©ç›Šã«å¯¾ã™ã‚‹å ±é…¬
  - ãƒªã‚¹ã‚¯ç®¡ç†ï¼ˆé©åˆ‡ãªã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ï¼‰ã¸ã®å ±é…¬
  - ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã¸ã®ãƒšãƒŠãƒ«ãƒ†ã‚£

#### 3.3.4 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è©•ä¾¡ã¨é¸æŠ
- [ ] å„ã‚·ãƒŠãƒªã‚ªã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç‹¬ç«‹è©•ä¾¡
- [ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå­¦ç¿’ç‡ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ãªã©ï¼‰
- [ ] å­¦ç¿’æ›²ç·šã®ç›£è¦–ã¨æ—©æœŸåœæ­¢

**å®Ÿè£…ã‚¿ã‚¹ã‚¯**
- [ ] ã‚·ãƒŠãƒªã‚ª1_1å°‚ç”¨ç’°å¢ƒã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª1_2å°‚ç”¨ç’°å¢ƒã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª2_1å°‚ç”¨ç’°å¢ƒã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª2_2å°‚ç”¨ç’°å¢ƒã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª3_1å°‚ç”¨ç’°å¢ƒã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª3_2å°‚ç”¨ç’°å¢ƒã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- [ ] ã‚·ãƒŠãƒªã‚ª3_3å°‚ç”¨ç’°å¢ƒã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

**æ³¨æ„**: å¼·åŒ–å­¦ç¿’ã¯åæŸãŒé›£ã—ãã€å„ã‚·ãƒŠãƒªã‚ªã”ã¨ã«æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€ã¾ãšã¯ã‚¢ãƒ—ãƒ­ãƒ¼ãƒAï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼‰ã®å®Œæˆã‚’å„ªå…ˆã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨

### 3.4 çµ±åˆã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ

#### 3.4.1 Layer 2ã®çµ±åˆå®Ÿè£…
```python
class Layer2Optimizer:
    """å„ã‚·ãƒŠãƒªã‚ªã«å¯¾å¿œã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«ã‚’ç®¡ç†"""
    def __init__(self):
        # ã‚·ãƒŠãƒªã‚ªã”ã¨ã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        with open('models/layer2/optimal_params.json', 'r') as f:
            self.optimal_params = json.load(f)
        
        # ã¾ãŸã¯ã€å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒBã®å ´åˆï¼‰
        # self.rl_agents = {
        #     'scenario_1_1': PPO.load('models/layer2/rl_agent_scenario_1_1'),
        #     'scenario_1_2': PPO.load('models/layer2/rl_agent_scenario_1_2'),
        #     ...
        # }
    
    def get_parameters(self, scenario_id, market_condition=None):
        """
        æŒ‡å®šã•ã‚ŒãŸã‚·ãƒŠãƒªã‚ªã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            scenario_id: ã‚·ãƒŠãƒªã‚ªIDï¼ˆ'1_1', '1_2'ãªã©ï¼‰
            market_condition: å¸‚å ´ç’°å¢ƒï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€å‹•çš„èª¿æ•´ç”¨ï¼‰
        
        Returns:
            æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸
        """
        base_params = self.optimal_params.get(f'scenario_{scenario_id}', {})
        
        # å¸‚å ´ç’°å¢ƒã«å¿œã˜ãŸå‹•çš„èª¿æ•´ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if market_condition:
            base_params = self.adjust_for_market_condition(base_params, market_condition)
        
        return base_params
    
    def adjust_for_market_condition(self, params, market_condition):
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãªã©ã«å¿œã˜ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¾®èª¿æ•´"""
        if market_condition['volatility'] == 'high':
            params['stop_loss_atr'] *= 1.2  # ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹åºƒã‚ã‚‹
        elif market_condition['volatility'] == 'low':
            params['stop_loss_atr'] *= 0.8  # ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ç‹­ã‚ã‚‹
        
        return params
```

#### 3.4.2 å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
```python
def integrated_backtest(data, layer1_model, layer2_optimizer):
    """Layer 1ã¨Layer 2ã‚’çµ±åˆã—ãŸãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
    trades = []
    
    for i in range(len(data)):
        current_data = data[:i+1]
        features = create_features(current_data)
        
        # Layer 1: ã‚·ãƒŠãƒªã‚ªåˆ¤å®š
        scenario_id, probability = layer1_model.predict_proba(features[-1])
        
        if probability > 0.6:  # ç¢ºä¿¡åº¦é–¾å€¤
            # Layer 2: ã‚·ãƒŠãƒªã‚ªå°‚ç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
            optimal_params = layer2_optimizer.get_parameters(scenario_id)
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ¤å®š
            if check_entry_conditions(current_data, scenario_id, optimal_params):
                trade = execute_trade(current_data, scenario_id, optimal_params)
                trades.append(trade)
    
    return analyze_trades(trades)
```

- [ ] Layer 2ã‚’ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã«çµ±åˆ
- [ ] å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
  - Layer 1ã§ã‚·ãƒŠãƒªã‚ªåˆ¤å®š
  - Layer 2ã§ã‚·ãƒŠãƒªã‚ªå°‚ç”¨ã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é©ç”¨
  - ã‚¨ãƒ³ãƒˆãƒªãƒ¼/æ±ºæ¸ˆå®Ÿè¡Œ

#### 3.4.3 ã‚·ãƒŠãƒªã‚ªåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
- [ ] å„ã‚·ãƒŠãƒªã‚ªã®å€‹åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
  - ã‚·ãƒŠãƒªã‚ª1_1ã®å‹ç‡ã€åˆ©ç›Šç‡ã€å–å¼•å›æ•°
  - ã‚·ãƒŠãƒªã‚ª1_2ã®å‹ç‡ã€åˆ©ç›Šç‡ã€å–å¼•å›æ•°
  - ã‚·ãƒŠãƒªã‚ª2_1ã®å‹ç‡ã€åˆ©ç›Šç‡ã€å–å¼•å›æ•°
  - ã‚·ãƒŠãƒªã‚ª2_2ã®å‹ç‡ã€åˆ©ç›Šç‡ã€å–å¼•å›æ•°
  - ã‚·ãƒŠãƒªã‚ª3_1ã®å‹ç‡ã€åˆ©ç›Šç‡ã€å–å¼•å›æ•°
  - ã‚·ãƒŠãƒªã‚ª3_2ã®å‹ç‡ã€åˆ©ç›Šç‡ã€å–å¼•å›æ•°
  - ã‚·ãƒŠãƒªã‚ª3_3ã®å‹ç‡ã€åˆ©ç›Šç‡ã€å–å¼•å›æ•°

- [ ] ã‚·ãƒŠãƒªã‚ªé–“ã®æ¯”è¼ƒ
  - ã©ã®ã‚·ãƒŠãƒªã‚ªãŒæœ€ã‚‚åˆ©ç›Šã‚’å‡ºã—ã¦ã„ã‚‹ã‹
  - ã©ã®ã‚·ãƒŠãƒªã‚ªãŒæœ€ã‚‚å®‰å®šã—ã¦ã„ã‚‹ã‹
  - æ”¹å–„ãŒå¿…è¦ãªã‚·ãƒŠãƒªã‚ªã®ç‰¹å®š

#### 3.4.4 Phase 2ã¨ã®æ¯”è¼ƒ
- [ ] å…¨ä½“çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã®ç¢ºèª
  - åˆ©ç›Šã®å¢—åŠ 
  - ãƒªã‚¹ã‚¯èª¿æ•´å¾Œãƒªã‚¿ãƒ¼ãƒ³ï¼ˆã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªï¼‰ã®æ”¹å–„
  - æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã®å‰Šæ¸›
  - å‹ç‡ã®å‘ä¸Š

- [ ] ã‚·ãƒŠãƒªã‚ªã”ã¨ã®æ”¹å–„åº¦åˆã„
  - Layer 2å°å…¥å‰å¾Œã®æ¯”è¼ƒ

#### æˆæœç‰©
- Layer2çµ±åˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆï¼ˆPhase3_layer2_report.pdfï¼‰
- ã‚·ãƒŠãƒªã‚ªåˆ¥æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸€è¦§ï¼ˆoptimal_params.jsonï¼‰
- å„ã‚·ãƒŠãƒªã‚ªã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒè¡¨
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ„Ÿåº¦åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
- æ”¹å–„ææ¡ˆãƒªã‚¹ãƒˆ

---

## ğŸš€ Phase 4: ã‚·ã‚¹ãƒ†ãƒ çµ±åˆã¨ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ

**ç›®æ¨™**: å®Œå…¨ãªè‡ªå‹•å–å¼•ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã¨ãƒ‡ãƒ¢å£åº§ã§ã®ãƒ†ã‚¹ãƒˆ

### 4.1 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å–å¼•ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰

#### 4.1.1 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿å–å¾—
- [ ] MT5ã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ†ã‚£ãƒƒã‚¯å–å¾—
- [ ] å®šæœŸçš„ãªãƒ‡ãƒ¼ã‚¿æ›´æ–°ï¼ˆ1åˆ†ã”ã¨ãªã©ï¼‰
- [ ] è¤‡æ•°æ™‚é–“è»¸ã®åŒæœŸæ›´æ–°

#### 4.1.2 ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
```python
class RealTimeTradingSystem:
    def __init__(self):
        self.layer1_model = load_model('models/layer1/best_model.pkl')
        
        # Layer 2: ã‚·ãƒŠãƒªã‚ªã”ã¨ã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        with open('models/layer2/optimal_params.json', 'r') as f:
            self.layer2_params = json.load(f)
        
        # ã¾ãŸã¯ã‚·ãƒŠãƒªã‚ªåˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
        # self.layer2_params = {
        #     'scenario_1_1': json.load(open('models/layer2/scenario_1_1_params.json')),
        #     'scenario_1_2': json.load(open('models/layer2/scenario_1_2_params.json')),
        #     ...
        # }
        
    def run(self):
        while True:
            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            current_data = self.get_latest_data()
            
            # ç‰¹å¾´é‡è¨ˆç®—
            features = self.create_features(current_data)
            
            # Layer 1: ã‚·ãƒŠãƒªã‚ªåˆ¤å®š
            scenario, probability = self.layer1_model.predict_proba(features)
            
            if probability > 0.6:  # ç¢ºä¿¡åº¦é–¾å€¤
                # Layer 2: è©²å½“ã‚·ãƒŠãƒªã‚ªã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
                params = self.layer2_params[f'scenario_{scenario}']
                
                # ã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ¤å®šï¼ˆã‚·ãƒŠãƒªã‚ªå°‚ç”¨ã®ãƒ­ã‚¸ãƒƒã‚¯ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰
                if self.check_entry_conditions(current_data, scenario, params):
                    self.place_order(scenario, params)
            
            # æ—¢å­˜ãƒã‚¸ã‚·ãƒ§ãƒ³ã®ç®¡ç†
            self.manage_positions()
            
            time.sleep(60)  # 1åˆ†å¾…æ©Ÿ
```

#### 4.1.3 æ³¨æ–‡åŸ·è¡Œã‚·ã‚¹ãƒ†ãƒ 
- [ ] MT5ã¸ã®æ³¨æ–‡é€ä¿¡
- [ ] ãƒã‚¸ã‚·ãƒ§ãƒ³ç®¡ç†
  - ã‚ªãƒ¼ãƒ—ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³ã®è¿½è·¡
  - ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹/ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆã®è¨­å®š
  - ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ã®å®Ÿè£…

- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
  - æ¥ç¶šã‚¨ãƒ©ãƒ¼
  - æ³¨æ–‡æ‹’å¦
  - ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸å¯¾å¿œ

### 4.2 ãƒªã‚¹ã‚¯ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

- [ ] è³‡é‡‘ç®¡ç†ãƒ«ãƒ¼ãƒ«
  - æœ€å¤§ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚º
  - 1ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ãŸã‚Šã®æœ€å¤§ãƒªã‚¹ã‚¯ï¼ˆè³‡é‡‘ã®1-2%ï¼‰
  - åŒæ™‚ä¿æœ‰ãƒã‚¸ã‚·ãƒ§ãƒ³æ•°åˆ¶é™

- [ ] ãƒ‡ã‚¤ãƒªãƒ¼ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹
  - 1æ—¥ã®æœ€å¤§æå¤±é¡
  - é€£ç¶šæå¤±å›æ•°åˆ¶é™

- [ ] ç·Šæ€¥åœæ­¢æ©Ÿèƒ½
  - ç•°å¸¸ãªãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³æ¤œå‡º
  - ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•åœæ­¢

### 4.3 ãƒ­ã‚®ãƒ³ã‚°ã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

- [ ] å–å¼•ãƒ­ã‚°ã®è¨˜éŒ²
  - ã‚¨ãƒ³ãƒˆãƒªãƒ¼/æ±ºæ¸ˆã®è©³ç´°
  - åˆ¤æ–­ç†ç”±ï¼ˆã©ã®ã‚·ãƒŠãƒªã‚ªã€ã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
  - å„Layer ã®å‡ºåŠ›

- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
  - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æç›Š
  - å‹ç‡ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
  - ã‚ªãƒ¼ãƒ—ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³ä¸€è¦§

- [ ] ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½
  - é‡è¦ãªã‚·ã‚°ãƒŠãƒ«ç™ºç”Ÿæ™‚
  - ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚
  - ç›®æ¨™é”æˆ/æå¤±é–¾å€¤åˆ°é”æ™‚

### 4.4 ãƒ‡ãƒ¢å£åº§ã§ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ

- [ ] ãƒ‡ãƒ¢å£åº§ã§ã®ç¨¼åƒé–‹å§‹
- [ ] æ—¥æ¬¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼
- [ ] å•é¡Œç‚¹ã®æ´—ã„å‡ºã—
  - äºˆæœŸã—ãªã„å‹•ä½œ
  - ãƒ¢ãƒ‡ãƒ«ã®èª¤åˆ¤æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³
  - ã‚·ã‚¹ãƒ†ãƒ ãƒã‚°

- [ ] ç¶™ç¶šçš„ãªæ”¹å–„
  - ãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’
  - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¾®èª¿æ•´
  - ãƒã‚°ä¿®æ­£

#### æˆæœç‰©
- ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆï¼ˆPhase4_forward_test_report.pdfï¼‰
- ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«
- ã‚·ã‚¹ãƒ†ãƒ æ”¹å–„ææ¡ˆæ›¸

---

## ğŸ”„ Phase 5: ç¶™ç¶šçš„æ”¹å–„ã¨ãƒªã‚¢ãƒ«é‹ç”¨æº–å‚™ï¼ˆç¶™ç¶šçš„ï¼‰

### 5.1 ãƒ¢ãƒ‡ãƒ«ã®å®šæœŸæ›´æ–°ï¼ˆæœˆæ¬¡ï¼‰

- [ ] æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‰ãƒªãƒ•ãƒˆã®ç›£è¦–
  - ãƒ¢ãƒ‡ãƒ«ç²¾åº¦ã®ä½ä¸‹æ¤œå‡º
  - å¸‚å ´ç’°å¢ƒå¤‰åŒ–ã¸ã®é©å¿œ

- [ ] A/Bãƒ†ã‚¹ãƒˆ
  - æ–°æ—§ãƒ¢ãƒ‡ãƒ«ã®ä¸¦è¡Œé‹ç”¨
  - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

### 5.2 æ–°ã‚·ãƒŠãƒªã‚ªã®è¿½åŠ 

- [ ] å¸‚å ´åˆ†æã«ã‚ˆã‚‹æ–°ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹
- [ ] æ–°ã‚·ãƒŠãƒªã‚ªã®ãƒ«ãƒ¼ãƒ«åŒ–
- [ ] ãƒ¢ãƒ‡ãƒ«ã¸ã®çµ±åˆ

### 5.3 ãƒªã‚¢ãƒ«å£åº§ç§»è¡Œæº–å‚™

- [ ] æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
  - [ ] æœ€ä½3ãƒ¶æœˆã®ãƒ‡ãƒ¢å–å¼•ã§å®‰å®šã—ãŸåˆ©ç›Š
  - [ ] ã™ã¹ã¦ã®æ©Ÿèƒ½ãŒæ­£å¸¸å‹•ä½œ
  - [ ] ãƒªã‚¹ã‚¯ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒå …ç‰¢
  - [ ] ç·Šæ€¥æ™‚å¯¾å¿œãƒãƒ‹ãƒ¥ã‚¢ãƒ«å®Œå‚™

- [ ] å°‘é¡è³‡é‡‘ã§ã®æ®µéšçš„é‹ç”¨é–‹å§‹
- [ ] å¾ã€…ã«æŠ•å…¥è³‡é‡‘ã‚’å¢—åŠ 

---

## ğŸ“Š ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ä¸€è¦§

| Phase | ã‚¿ã‚¹ã‚¯ | æœŸé–“ | æˆåŠŸæŒ‡æ¨™ |
|-------|--------|------|----------|
| Phase 0 | ç’°å¢ƒæ§‹ç¯‰ | 1-2æ—¥ | ã™ã¹ã¦ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ |
| Phase 1 | ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚·ã‚¹ãƒ†ãƒ  | 2-3é€±é–“ | ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œã§ãã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å‹ç‡40%ä»¥ä¸Š |
| Phase 2 | Layer 1ï¼ˆç’°å¢ƒèªè­˜ï¼‰ | 2-3é€±é–“ | ãƒ¢ãƒ‡ãƒ«ç²¾åº¦70%ä»¥ä¸Šã€ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå‹ç‡ãŒ5-10%å‘ä¸Š |
| Phase 3 | Layer 2ï¼ˆæœ€é©åŒ–ï¼‰ | 2-3é€±é–“ | ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªå‘ä¸Šã€ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³å‰Šæ¸› |
| Phase 4 | ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ | 2é€±é–“+ | ãƒ‡ãƒ¢å£åº§ã§å®‰å®šå‹•ä½œã€Phase3ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ |
| Phase 5 | ãƒªã‚¢ãƒ«é‹ç”¨ | ç¶™ç¶šçš„ | å®‰å®šã—ãŸæœˆæ¬¡åˆ©ç›Š |

**ç·é–‹ç™ºæœŸé–“**: ç´„2.5-3ãƒ¶æœˆï¼ˆãƒ•ãƒ«ã‚¿ã‚¤ãƒ ã®å ´åˆï¼‰

---

## ğŸ› ï¸ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯è©³ç´°

### å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª
```python
# ãƒ‡ãƒ¼ã‚¿å‡¦ç†
pandas==2.0.0
numpy==1.24.0

# ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™
pandas-ta==0.3.14b
ta-lib==0.4.26  # ã¾ãŸã¯ ta-lib-binï¼ˆWindowsï¼‰

# æ©Ÿæ¢°å­¦ç¿’
scikit-learn==1.3.0
lightgbm==4.0.0
xgboost==1.7.6
optuna==3.3.0

# ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
backtesting==0.3.3
vectorbt==0.25.0  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³

# MT5é€£æº
MetaTrader5==5.0.45

# å¯è¦–åŒ–
matplotlib==3.7.0
seaborn==0.12.0
mplfinance==0.12.9
plotly==5.14.0

# ãã®ä»–
jupyter==1.0.0
joblib==1.3.0  # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
pyyaml==6.0  # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
```

### æ¨å¥¨é–‹ç™ºç’°å¢ƒ
- Python: 3.8 - 3.11
- RAM: 8GBä»¥ä¸Š
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸: 50GBä»¥ä¸Šï¼ˆãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨ï¼‰
- OS: Windows 10/11ï¼ˆMT5ã¨ã®äº’æ›æ€§ï¼‰

---

## âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …

### 1. ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã®å›é¿
- å¸¸ã«è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é›¢
- ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚’å¿…ãšå®Ÿæ–½
- ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å§‹ã‚ã‚‹

### 2. ãƒªã‚¹ã‚¯ç®¡ç†ã®å¾¹åº•
- ã©ã‚Œã ã‘AIãŒå„ªç§€ã§ã‚‚ã€ãƒªã‚¹ã‚¯ç®¡ç†ãªã—ã§ã¯ç ´ç”£ã™ã‚‹
- 1ãƒˆãƒ¬ãƒ¼ãƒ‰ã®ãƒªã‚¹ã‚¯ã¯å£åº§ã®1-2%ä»¥å†…
- æ„Ÿæƒ…ã‚’æ’é™¤ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã‚’ä¿¡é ¼ã™ã‚‹

### 3. ç¾å®Ÿçš„ãªæœŸå¾…å€¤
- AIã¯é­”æ³•ã§ã¯ãªã„
- å‹ç‡60-70%ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼1.5-2.0ãŒç¾å®Ÿçš„
- æœˆåˆ©5-10%ã‚’å®‰å®šã—ã¦é”æˆã§ãã‚Œã°å„ªç§€

### 4. æ³•ä»¤éµå®ˆ
- è‡ªå‹•å£²è²·ãŒè¨±å¯ã•ã‚Œã¦ã„ã‚‹ãƒ–ãƒ­ãƒ¼ã‚«ãƒ¼ã‚’ä½¿ç”¨
- ç¨å‹™ç”³å‘Šã‚’é©åˆ‡ã«è¡Œã†

---

## ğŸ“š å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹

### æ›¸ç±
- ã€Œã‚·ã‚¹ãƒ†ãƒ ãƒˆãƒ¬ãƒ¼ãƒ‰ åŸºæœ¬ã¨åŸå‰‡ã€ãƒã‚¤ã‚±ãƒ«ãƒ»ã‚³ãƒ™ãƒ«
- ã€Œã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å…¥é–€ã€ã‚¢ãƒ¼ãƒ‹ãƒ¼ãƒ»ãƒãƒ£ãƒ³
- ã€ŒPython for Financeã€Yves Hilpisch

### ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒªã‚½ãƒ¼ã‚¹
- [Backtesting.py Documentation](https://kernc.github.io/backtesting.py/)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- [Optuna Tutorial](https://optuna.org/)
- [MT5 Python Documentation](https://www.mql5.com/en/docs/python_metatrader5)

---

## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰ï¼ˆæ•™å¸«ãªã—ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ–¹å¼ï¼‰

#### ã‚¹ãƒ†ãƒƒãƒ—1: ç’°å¢ƒæ§‹ç¯‰ï¼ˆPhase 0ï¼‰
```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir fx_trading_system
cd fx_trading_system

# ä»®æƒ³ç’°å¢ƒä½œæˆ
python -m venv venv
venv\Scripts\activate

# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install pandas numpy xgboost scikit-learn matplotlib seaborn MetaTrader5 gym optuna backtesting joblib
```

#### ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆPhase 1ã®å‰åŠï¼‰
```python
# MT5ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
import MetaTrader5 as mt5
mt5.initialize()
data = mt5.copy_rates_range("USDJPY", mt5.TIMEFRAME_M15, ...)
```

#### ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œï¼ˆPhase 2ï¼‰

**ã‚ãªãŸã®ä½œæ¥­**:
1. âœ… é‡è¦ãªç‰¹å¾´é‡ã‚’é¸æŠï¼ˆconfig/feature_selection.pyï¼‰
2. â¸ï¸ AIãŒã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œï¼ˆ5åˆ†ï¼‰
3. âœ… å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ç‰¹æ€§ã‚’ç¢ºèª
4. âœ… å„ã‚¯ãƒ©ã‚¹ã‚¿ã«åå‰ã‚’ä»˜ã‘ã‚‹
5. âœ… ãƒˆãƒ¬ãƒ¼ãƒ‰ä¸å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã‚¿ã‚’é™¤å¤–

**AIã®ä½œæ¥­**:
- K-Meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
- ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®æœ€é©åŒ–ï¼ˆ5-12å€‹ã‚’ãƒ†ã‚¹ãƒˆï¼‰
- ã‚¯ãƒ©ã‚¹ã‚¿ç‰¹æ€§ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
- ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢è¨ˆç®—

```python
from src.clustering.market_regime_detector import MarketRegimeDetector
from config.feature_selection import SELECTED_FEATURES

# 1. ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
detector = MarketRegimeDetector(n_clusters=7)
clusters = detector.fit_clusters(historical_data, SELECTED_FEATURES)

# 2. åˆ†æ
analysis = detector.analyze_clusters(historical_data, clusters)

# 3. ã‚ãªãŸãŒãƒ©ãƒ™ãƒ«ä»˜ã‘
cluster_labels = create_cluster_labels(detector)
```

#### ã‚¹ãƒ†ãƒƒãƒ—4: RLè¨“ç·´ï¼ˆPhase 3ï¼‰

**AIã®ä½œæ¥­**ï¼ˆè‡ªå‹•ï¼‰:
```python
# å„ã‚¯ãƒ©ã‚¹ã‚¿ã§RLã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´
agents, results = train_all_cluster_agents(
    data=historical_data,
    detector=detector,
    cluster_labels=cluster_labels,
    n_episodes=1000
)
```

**ã‚ãªãŸã®ä½œæ¥­**:
- è¨“ç·´çµæœã‚°ãƒ©ãƒ•ã‚’ç¢ºèª
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæ‚ªã„ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ç‰¹å®š
- å¿…è¦ã«å¿œã˜ã¦å ±é…¬é–¢æ•°ã‚’èª¿æ•´

---

## ğŸ”„ æ•™å¸«ãªã—ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° vs å¾“æ¥å‹ã®æ¯”è¼ƒ

| é …ç›® | æ•™å¸«ãªã—ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° | å¾“æ¥å‹ï¼ˆã‚·ãƒŠãƒªã‚ªå®šç¾©ï¼‰ |
|------|----------------------|---------------------|
| **ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©** | AIãŒè‡ªå‹•ç™ºè¦‹ | æ‰‹å‹•ã§å®šç¾© |
| **å®Ÿè£…æ™‚é–“** | çŸ­ã„ï¼ˆãƒ©ãƒ™ãƒªãƒ³ã‚°ã®ã¿ï¼‰ | é•·ã„ï¼ˆå…¨ãƒ«ãƒ¼ãƒ«å®Ÿè£…ï¼‰ |
| **ç²¾åº¦ä¸Šé™** | ãƒ‡ãƒ¼ã‚¿ä¾å­˜ï¼ˆé«˜ã„ï¼‰ | ãƒ«ãƒ¼ãƒ«ä¾å­˜ï¼ˆåˆ¶é™ã‚ã‚Šï¼‰ |
| **æ–°ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œ** | è‡ªå‹•çš„ã«ç™ºè¦‹ | æ‰‹å‹•ã§è¿½åŠ  |
| **ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹** | å†ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®ã¿ | ãƒ«ãƒ¼ãƒ«æ›´æ–°ãŒå¿…è¦ |
| **ã‚ãªãŸã®ä½œæ¥­** | ç‰¹å¾´é‡é¸æŠï¼‹ãƒ©ãƒ™ãƒ«ä»˜ã‘ | å…¨ã‚·ãƒŠãƒªã‚ªã®ãƒ«ãƒ¼ãƒ«å®Ÿè£… |
| **æ¨å¥¨åº¦** | â­â­â­â­â­ | â­â­â­ |

---

## ğŸ“Š ä½œæ¥­åˆ†æ‹…ã®æ˜ç¢ºåŒ–

### ã‚ãªãŸãŒè¡Œã†ä½œæ¥­ï¼ˆãƒˆãƒ¬ãƒ¼ãƒ‰çŸ¥è­˜ãŒå¿…è¦ï¼‰

#### Phase 2: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
- [ ] é‡è¦ãªç‰¹å¾´é‡ã‚’é¸æŠï¼ˆ30-50å€‹ï¼‰
- [ ] ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’èª­ã‚€
- [ ] å„ã‚¯ãƒ©ã‚¹ã‚¿ã«æ„å‘³ã®ã‚ã‚‹åå‰ã‚’ä»˜ã‘ã‚‹
- [ ] ãƒˆãƒ¬ãƒ¼ãƒ‰ä¸å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã‚¿ã‚’ç‰¹å®š

#### Phase 3: RLè¨“ç·´
- [ ] è¨“ç·´çµæœã‚°ãƒ©ãƒ•ã‚’ç¢ºèª
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæ‚ªã„ã‚¯ãƒ©ã‚¹ã‚¿ã‚’åˆ†æ
- [ ] å ±é…¬é–¢æ•°ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

#### Phase 4-5: æœ¬ç•ªé‹ç”¨
- [ ] ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆçµæœã®ç›£è¦–
- [ ] å®šæœŸçš„ãªå†è¨“ç·´ï¼ˆæœˆ1å›ï¼‰
- [ ] ãƒªã‚¹ã‚¯ç®¡ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´

### AIãŒè¡Œã†ä½œæ¥­ï¼ˆè‡ªå‹•åŒ–ï¼‰

#### Phase 2: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
- âœ… K-Meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
- âœ… ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®æœ€é©åŒ–ï¼ˆã‚¨ãƒ«ãƒœãƒ¼æ³•ã€ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ï¼‰
- âœ… ã‚¯ãƒ©ã‚¹ã‚¿ç‰¹æ€§ã®è‡ªå‹•åˆ†æ
- âœ… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹ã‚¯ãƒ©ã‚¹ã‚¿æ¤œè¨¼

#### Phase 3: RLè¨“ç·´
- âœ… ç’°å¢ƒæ§‹ç¯‰ï¼ˆGymï¼‰
- âœ… XGBoost Q-Learningå®Ÿè£…
- âœ… å„ã‚¯ãƒ©ã‚¹ã‚¿ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨“ç·´ï¼ˆ1000ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰
- âœ… å­¦ç¿’æ›²ç·šã®ç”Ÿæˆ

#### Phase 4: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
- âœ… çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

---

## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **Phase 0ã‚’å®Œäº†ã™ã‚‹**
   - ã“ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’ä¿å­˜
   - é–‹ç™ºç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
   - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’ä½œæˆ

2. **æœ€åˆã®ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã**
   - MT5ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
   - ç°¡å˜ãªãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã®è¨ˆç®—

3. **å°ã•ãå§‹ã‚ã¦å¾ã€…ã«æ‹¡å¤§**
   - æœ€åˆã¯1ã¤ã®ã‚·ãƒŠãƒªã‚ªã ã‘å®Ÿè£…
   - å‹•ä½œç¢ºèªå¾Œã€ä»–ã®ã‚·ãƒŠãƒªã‚ªã‚’è¿½åŠ 

**é‡è¦**: å®Œç’§ã‚’ç›®æŒ‡ã•ãšã€ã¾ãšã¯å‹•ãã‚‚ã®ã‚’ä½œã‚‹ã€‚ãã®å¾Œã€åå¾©çš„ã«æ”¹å–„ã—ã¦ã„ãã€‚

---

**ä½œæˆè€…ãƒ¡ãƒ¢**: ã“ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã¯å®Ÿè·µçš„ã‹ã¤æ®µéšçš„ã«é€²ã‚ã‚‰ã‚Œã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚å„ãƒ•ã‚§ãƒ¼ã‚ºã‚’ç€å®Ÿã«å®Œäº†ã•ã›ã€ç„¦ã‚‰ãšç¢ºå®Ÿã«é€²ã‚ã¦ãã ã•ã„ã€‚æˆåŠŸã‚’ç¥ˆã£ã¦ã„ã¾ã™ï¼
